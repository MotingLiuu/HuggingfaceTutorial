{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型下载与加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a94f068cc944c839cda37f38759b505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/828 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0da5380342a347bc82750886b34117b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/828 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b57b9598c0324772ac57290ac45cfd13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/156M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained('hfl/rbt3', force_download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: 'git lfs clone' is deprecated and will not be updated\n",
      "          with new flags from 'git clone'\n",
      "\n",
      "'git clone' has been updated in upstream Git to have comparable\n",
      "speeds to 'git lfs clone'.\n",
      "Cloning into 'rbt3'...\n",
      "remote: Enumerating objects: 48, done.\u001b[K\n",
      "remote: Total 48 (delta 0), reused 0 (delta 0), pack-reused 48 (from 1)\u001b[K\n",
      "Unpacking objects: 100% (48/48), 156.45 KiB | 1.06 MiB/s, done.\n",
      "Downloading LFS objects: 100% (1/1), 156 MB | 13 MB/s                           \r"
     ]
    }
   ],
   "source": [
    "!git lfs clone \"https://huggingface.co/hfl/rbt3\" --include=\"*.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-2): 3 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained('rbt3')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"rbt3\",\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"directionality\": \"bidi\",\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 3,\n",
       "  \"output_attentions\": true,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"pooler_fc_size\": 768,\n",
       "  \"pooler_num_attention_heads\": 12,\n",
       "  \"pooler_num_fc_layers\": 3,\n",
       "  \"pooler_size_per_head\": 128,\n",
       "  \"pooler_type\": \"first_token_transform\",\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.45.2\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 21128\n",
       "}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained('rbt3', output_attentions=True)\n",
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"rbt3\",\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"directionality\": \"bidi\",\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 3,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"pooler_fc_size\": 768,\n",
       "  \"pooler_num_attention_heads\": 12,\n",
       "  \"pooler_num_fc_layers\": 3,\n",
       "  \"pooler_size_per_head\": 128,\n",
       "  \"pooler_type\": \"first_token_transform\",\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.45.2\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 21128\n",
       "}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained('rbt3')\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen = '我欲乘风归去，又恐琼楼玉宇，高处不胜寒。'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2769, 3617,  733, 7599, 2495, 1343, 8024, 1348, 2607, 4437, 3517,\n",
       "         4373, 2126, 8024, 7770, 1905,  679, 5526, 2170,  511,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('rbt3')\n",
    "inputs = tokenizer(sen, return_tensors='pt')\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertSdpaSelfAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support non-absolute `position_embedding_type` or `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.4675,  1.0141, -0.0058,  ...,  0.1654,  0.2695,  0.0843],\n",
       "         [ 0.4492,  0.0087, -0.2444,  ..., -0.2155, -0.4300, -0.0175],\n",
       "         [-0.2932, -0.0460, -0.8318,  ...,  0.3941, -0.0197, -0.1786],\n",
       "         ...,\n",
       "         [-0.0657, -0.5814, -0.7339,  ...,  0.7724, -0.1228, -0.3468],\n",
       "         [ 0.2979,  0.2610, -0.7817,  ..., -0.0129, -0.0135, -0.3109],\n",
       "         [ 0.4630,  1.0184, -0.0088,  ...,  0.1672,  0.2708,  0.0854]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-8.8071e-02, -9.3004e-01, -9.9997e-01, -9.4734e-01, -7.9155e-01,\n",
       "         -2.0181e-02,  1.8273e-01, -2.7196e-01,  9.8799e-01,  9.9717e-01,\n",
       "          1.1182e-01, -1.0000e+00, -1.8678e-01,  9.9874e-01, -9.9999e-01,\n",
       "          9.9983e-01,  7.8124e-01,  9.7588e-01, -9.9137e-01, -5.9165e-02,\n",
       "         -9.9753e-01, -9.5086e-02, -6.9507e-02,  9.8925e-01,  9.9832e-01,\n",
       "         -9.9527e-01, -9.9819e-01, -2.1769e-02, -9.4477e-01, -9.9989e-01,\n",
       "         -9.3475e-01, -9.9818e-01, -2.1449e-01,  2.7004e-01,  9.9808e-01,\n",
       "         -9.4182e-01, -1.6109e-01, -9.7537e-01, -7.5599e-01, -9.9699e-01,\n",
       "         -1.2927e-01,  9.7804e-01,  5.2309e-02,  9.9958e-01,  1.2419e-02,\n",
       "          1.6658e-01,  9.9983e-01,  9.9716e-01,  1.9914e-01, -9.9668e-01,\n",
       "          8.1591e-02, -2.9870e-01, -9.3792e-01,  9.8901e-01,  1.5361e-01,\n",
       "          1.1624e-01,  9.9592e-01, -9.9996e-01, -9.9900e-01,  9.9382e-01,\n",
       "         -9.9910e-01,  9.8430e-01,  9.6573e-01,  9.9854e-01, -9.4498e-01,\n",
       "          9.9985e-01,  9.9089e-01,  7.9200e-01, -1.4306e-01, -9.9999e-01,\n",
       "          2.4702e-01, -8.9185e-01, -9.9976e-01,  9.3676e-02, -1.0036e-01,\n",
       "         -9.9968e-01,  9.9629e-01, -1.2471e-01,  9.9857e-01,  4.0931e-01,\n",
       "         -9.9981e-01, -1.9416e-02, -1.4906e-01,  1.8277e-01,  9.8704e-01,\n",
       "          9.9987e-01, -1.2285e-01, -9.9208e-01, -2.3926e-01, -9.9944e-01,\n",
       "          1.6915e-03,  9.9618e-01,  9.9998e-01, -9.9539e-01,  9.9997e-01,\n",
       "         -7.3283e-01,  1.2526e-01, -1.2448e-01, -9.3294e-01,  9.8590e-01,\n",
       "         -7.1023e-02,  8.3970e-02,  9.9999e-01,  9.9978e-01, -8.6410e-01,\n",
       "         -9.9785e-01, -9.9804e-01,  9.9645e-01, -9.9893e-01,  5.8787e-02,\n",
       "          9.9996e-01,  9.8327e-01,  1.0000e+00,  9.9799e-01,  9.9996e-01,\n",
       "         -9.9994e-01, -3.0990e-01,  1.0044e-01, -9.9841e-01,  9.9905e-01,\n",
       "         -8.2349e-01,  3.4312e-01, -8.9581e-01, -2.2379e-01, -5.5650e-02,\n",
       "         -9.9997e-01,  5.6618e-02, -3.0611e-01, -9.9181e-01, -9.9626e-01,\n",
       "         -9.8099e-01, -9.9288e-01,  9.9508e-01, -5.2224e-01,  2.8148e-01,\n",
       "         -1.6422e-02,  8.8674e-02, -3.2508e-03, -9.9996e-01, -9.9875e-01,\n",
       "         -9.9956e-01,  9.9203e-01,  5.7787e-01,  9.6784e-01, -9.7570e-01,\n",
       "          9.9962e-01, -9.9941e-01,  9.9935e-01,  9.8858e-01, -1.5363e-01,\n",
       "         -9.7691e-01,  9.2552e-02, -9.9772e-01, -1.3584e-01,  2.3427e-01,\n",
       "          9.9145e-01,  9.7685e-01,  8.9901e-01, -9.8653e-01,  9.9969e-01,\n",
       "         -9.9759e-01,  8.9926e-01,  1.5320e-01,  9.9886e-01,  1.0000e+00,\n",
       "         -9.9998e-01,  8.2798e-02, -9.9998e-01, -4.5016e-01, -3.2107e-01,\n",
       "          9.9730e-01,  9.9433e-01,  9.8534e-01,  9.9951e-01, -7.9309e-01,\n",
       "         -9.9638e-01,  9.7760e-01, -9.9979e-01,  7.2347e-01,  9.9997e-01,\n",
       "          3.1689e-01,  7.9250e-01,  9.9964e-01, -8.4280e-01,  9.9381e-01,\n",
       "         -3.7860e-02, -2.2647e-01, -9.9239e-01, -1.5977e-01, -4.8639e-01,\n",
       "          9.7660e-01, -9.8467e-01, -7.0340e-02,  8.3486e-01,  3.2667e-02,\n",
       "         -1.4431e-01, -9.9940e-01, -9.9971e-01,  9.9932e-01,  9.9053e-01,\n",
       "          8.0377e-01, -1.9414e-01,  9.9999e-01,  7.7563e-01,  9.9994e-01,\n",
       "         -5.8700e-02,  4.6805e-01, -7.0372e-02,  9.9729e-01,  5.1740e-04,\n",
       "          9.3270e-01,  1.9047e-01,  9.9987e-01, -9.8058e-01, -9.9994e-01,\n",
       "         -1.4565e-01,  9.9458e-01, -1.6338e-01, -9.9166e-01, -4.5744e-01,\n",
       "         -2.2108e-01,  9.9951e-01,  9.8385e-02, -6.3032e-01,  9.9646e-01,\n",
       "         -9.9851e-01,  7.5357e-01, -9.9986e-01, -9.9508e-01,  9.9926e-01,\n",
       "         -3.1574e-01, -1.0000e+00,  9.3815e-01,  9.9971e-01, -3.0284e-01,\n",
       "          9.9652e-01,  1.2565e-01, -9.9833e-01, -1.1218e-01, -4.6638e-02,\n",
       "         -9.9999e-01, -9.5318e-01, -1.0000e+00, -9.2300e-02, -1.3641e-01,\n",
       "          7.4068e-01, -1.0000e+00, -3.9821e-02, -9.9966e-01,  9.9514e-01,\n",
       "          9.9957e-01,  3.1940e-02,  5.0626e-02,  9.9993e-01, -4.5387e-01,\n",
       "         -8.7332e-02, -9.1049e-01,  2.9119e-01, -1.2946e-01,  9.9162e-01,\n",
       "         -3.7584e-02,  9.9867e-01, -9.9935e-01,  8.8741e-02,  7.9190e-01,\n",
       "         -9.9980e-01,  1.2526e-01,  9.8314e-01, -1.6491e-01, -1.1348e-01,\n",
       "         -1.4073e-02, -1.1696e-01,  8.0826e-01,  9.9808e-01,  1.0000e+00,\n",
       "          9.9491e-01,  9.9987e-01,  9.9998e-01, -1.5214e-02, -9.9496e-01,\n",
       "         -8.7391e-01,  1.8854e-01, -1.0000e+00, -9.5821e-01, -9.9301e-01,\n",
       "          9.8423e-01,  1.7414e-01,  1.0000e+00, -1.0000e+00,  9.9988e-01,\n",
       "         -9.6826e-01, -9.7625e-02, -3.2991e-02,  1.9463e-01, -3.8552e-01,\n",
       "          7.4516e-02,  9.8880e-01, -2.8921e-02,  9.7957e-01,  9.8342e-01,\n",
       "         -8.2949e-02, -7.7110e-02,  4.5104e-01, -1.8621e-01,  9.8485e-01,\n",
       "         -9.5571e-01,  9.9584e-01, -1.0414e-01,  9.9834e-01,  1.3483e-01,\n",
       "         -1.0000e+00,  9.9647e-01, -9.9962e-01, -3.0141e-01, -9.9843e-01,\n",
       "         -9.9493e-01,  2.8375e-01, -9.9786e-01,  4.9427e-01,  9.6741e-01,\n",
       "          2.2739e-01,  3.1124e-01, -9.9994e-01, -9.7724e-01,  8.5400e-01,\n",
       "          9.9970e-01, -9.9873e-01,  9.8097e-01,  9.9191e-01, -9.9087e-01,\n",
       "         -5.5008e-03,  9.0940e-01, -9.9829e-01,  9.7055e-01, -9.9979e-01,\n",
       "          1.0196e-01,  9.9958e-01, -6.5265e-02, -9.9936e-01, -9.4583e-01,\n",
       "          5.0099e-02,  8.9025e-01,  3.2010e-02,  9.9999e-01, -1.1530e-01,\n",
       "         -2.3274e-01, -9.9979e-01, -9.6282e-01, -9.0899e-01, -1.9246e-02,\n",
       "          9.9771e-01, -9.9970e-01, -1.1685e-01,  9.9704e-01, -9.9986e-01,\n",
       "         -1.0356e-01,  2.3202e-02, -3.6690e-01, -8.7576e-02, -9.8700e-01,\n",
       "         -9.9988e-01, -9.9954e-01,  9.9992e-01,  1.4243e-01, -2.0091e-01,\n",
       "          9.9836e-01,  9.9953e-01,  9.9950e-01, -9.1757e-01,  9.6589e-01,\n",
       "          9.9901e-01,  2.7066e-01,  1.8866e-01, -9.8815e-01, -1.2738e-01,\n",
       "         -5.9037e-01, -9.8984e-01, -1.1867e-02,  7.4347e-01, -8.4613e-01,\n",
       "         -9.7816e-01,  9.9946e-01,  9.9762e-01,  1.0000e+00,  5.8232e-02,\n",
       "         -8.8397e-01,  9.1627e-01, -9.1926e-01, -9.9247e-01, -1.2903e-01,\n",
       "          9.9836e-01, -9.8969e-01,  1.2010e-02, -3.7793e-01, -6.5051e-01,\n",
       "          9.9364e-01, -9.9584e-01,  6.3865e-02, -9.9999e-01, -9.9950e-01,\n",
       "         -9.9995e-01,  9.9933e-01, -9.0197e-03, -5.9559e-02, -9.9953e-01,\n",
       "          1.0000e+00,  9.9706e-01, -9.7955e-01, -2.8554e-01,  9.9963e-01,\n",
       "         -6.7079e-03, -9.4057e-01, -9.9998e-01, -9.9938e-01,  9.5457e-01,\n",
       "         -7.7452e-02,  9.9998e-01,  9.6309e-01, -9.9907e-01,  9.4788e-01,\n",
       "          9.6763e-01,  3.4924e-01, -9.9744e-01, -9.7449e-01, -1.5411e-01,\n",
       "         -9.0921e-02, -3.6622e-02,  1.0172e-02,  3.1738e-01,  9.9996e-01,\n",
       "         -1.5066e-01,  5.8620e-02,  6.2757e-02,  9.9988e-01,  6.8090e-01,\n",
       "         -9.9748e-01,  1.9067e-01,  3.9341e-02, -9.9212e-01, -9.9846e-01,\n",
       "         -9.9935e-01, -4.3203e-02,  1.6124e-01, -8.3430e-02, -9.9412e-01,\n",
       "         -9.9463e-01, -9.9860e-01,  9.3141e-03, -9.9529e-01, -9.8976e-01,\n",
       "         -1.7478e-02, -9.8723e-01, -9.9952e-01,  9.9914e-01, -9.9894e-01,\n",
       "         -9.0015e-03,  8.4133e-01,  9.9834e-01, -9.9746e-01,  3.4091e-01,\n",
       "          9.8659e-01, -9.9328e-01, -1.4238e-01, -9.6182e-01,  1.0063e-01,\n",
       "         -8.3938e-01, -9.9997e-01, -3.3924e-02,  9.9979e-01,  9.9816e-01,\n",
       "          9.9434e-01,  9.3028e-01, -8.9911e-01,  8.0563e-01,  9.9660e-01,\n",
       "          9.9999e-01, -2.3115e-01, -1.1422e-02, -9.9999e-01, -5.5310e-01,\n",
       "          9.6172e-01,  2.1643e-02,  9.2545e-01, -9.9859e-01,  2.5975e-01,\n",
       "         -9.9391e-01, -9.0683e-02,  1.0000e+00,  9.9821e-01,  7.3000e-01,\n",
       "         -9.9997e-01, -1.2803e-01, -5.1382e-01,  1.7677e-01, -9.3963e-01,\n",
       "          3.7302e-02,  9.9991e-01, -5.2293e-01,  4.4432e-01, -9.9150e-01,\n",
       "         -9.9955e-01,  9.9998e-01, -9.9935e-01,  9.9998e-01,  9.5229e-01,\n",
       "         -9.9178e-01,  5.7289e-02, -9.9760e-01, -1.6557e-01, -2.5147e-01,\n",
       "         -3.1193e-02,  1.8665e-01, -1.0434e-03, -9.9999e-01, -2.2667e-02,\n",
       "          9.7866e-01, -5.3943e-02, -3.2156e-01, -9.8977e-01,  9.2062e-02,\n",
       "          9.9750e-01, -9.9868e-01, -9.9965e-01, -1.3570e-01, -9.5387e-02,\n",
       "         -2.6968e-01,  3.8256e-01,  3.9084e-02,  3.6458e-01, -9.8638e-01,\n",
       "          7.9993e-02,  8.9161e-01, -9.7619e-01,  6.6304e-01, -6.5672e-01,\n",
       "         -8.4421e-01,  2.3099e-01,  9.9985e-01,  9.9994e-01, -9.9951e-01,\n",
       "         -9.9970e-01, -6.8407e-01,  8.7859e-02,  2.2103e-01,  9.9694e-01,\n",
       "         -2.8486e-03, -9.9026e-01, -3.2628e-02, -5.6648e-03, -1.7556e-01,\n",
       "         -7.3369e-01,  9.9996e-01, -9.8143e-01,  9.9998e-01, -9.9996e-01,\n",
       "         -9.9331e-01,  1.1617e-01,  9.9980e-01, -9.9992e-01,  2.0703e-01,\n",
       "          9.9639e-01, -9.9902e-01, -1.0205e-01, -9.6450e-01,  7.7164e-01,\n",
       "          4.8999e-03, -1.2384e-01,  3.6418e-01, -9.9781e-01,  7.9844e-02,\n",
       "         -9.9939e-01,  7.6582e-01,  9.9512e-01, -9.9822e-01, -9.1079e-01,\n",
       "         -9.9931e-01,  1.0467e-01,  1.9892e-01, -9.9590e-01,  9.4951e-01,\n",
       "          9.9999e-01,  2.4779e-01,  8.9094e-01, -9.9934e-01, -9.8903e-02,\n",
       "         -1.8170e-01, -9.9065e-01,  4.8935e-02, -9.9976e-01,  9.4774e-01,\n",
       "         -9.7960e-01,  9.9832e-01, -9.9996e-01,  9.5190e-01,  9.6884e-01,\n",
       "         -1.5791e-01, -3.0540e-01, -1.5109e-01,  7.7108e-01, -9.9976e-01,\n",
       "         -2.9319e-01, -9.9571e-01, -9.9911e-01, -2.1519e-01,  9.9985e-01,\n",
       "          9.6715e-01,  3.8091e-02,  9.9904e-01, -8.9794e-01,  3.3504e-02,\n",
       "          2.9690e-01,  3.6775e-01,  1.0000e+00, -9.9828e-01, -9.9996e-01,\n",
       "          9.8442e-01, -9.9968e-01, -9.6095e-01,  9.9996e-01,  3.8869e-01,\n",
       "          9.8596e-01,  1.0915e-01, -9.9199e-01,  5.8883e-02,  8.9000e-02,\n",
       "          9.9921e-01, -2.8589e-01, -2.6844e-01,  9.9997e-01, -8.8987e-02,\n",
       "          1.8998e-01, -5.4699e-02,  9.9688e-01, -5.0047e-02, -1.4103e-01,\n",
       "          9.7825e-01, -5.7326e-01, -9.9036e-01, -9.9951e-01, -1.4324e-01,\n",
       "          3.6437e-02, -2.4226e-01, -7.5459e-03,  8.8353e-01,  9.9994e-01,\n",
       "         -9.9442e-01,  9.7623e-01, -1.0000e+00, -9.9871e-01, -7.5336e-02,\n",
       "         -4.4723e-02,  9.9894e-01,  7.9585e-03, -9.8725e-01,  1.0792e-01,\n",
       "         -9.8922e-01,  9.6006e-01, -9.9956e-01,  9.7469e-01,  1.3854e-01,\n",
       "          1.4058e-02,  9.9997e-01,  9.7590e-01, -3.7066e-02, -9.6998e-01,\n",
       "         -9.0025e-01, -2.9404e-02, -9.9886e-01,  9.9936e-01,  7.4335e-02,\n",
       "          6.8973e-02,  8.0578e-03,  1.8934e-01, -9.9980e-01, -7.4278e-01,\n",
       "          5.4462e-02,  9.9382e-01, -9.9970e-01,  9.9777e-01, -9.7081e-01,\n",
       "          9.9896e-01,  9.9809e-01,  9.9999e-01,  3.0664e-02,  9.3919e-01,\n",
       "         -9.9600e-01, -9.9707e-01,  9.4291e-01,  9.4834e-01,  9.9910e-01,\n",
       "          9.6940e-01,  9.9642e-01,  9.2325e-02, -9.9919e-01, -2.1892e-01,\n",
       "         -1.6882e-01, -1.6953e-02,  1.0317e-01, -7.3714e-01, -9.9995e-01,\n",
       "          9.9955e-01, -9.9989e-01, -9.9986e-01, -8.3051e-01, -9.9992e-01,\n",
       "          9.9118e-01, -1.6215e-01,  9.9693e-01,  9.0800e-01, -9.9647e-01,\n",
       "         -9.8904e-01, -8.6761e-02, -8.9584e-01, -9.9307e-01,  8.9126e-02,\n",
       "         -1.0000e+00,  4.0777e-03,  5.4882e-02, -7.5475e-01,  3.1377e-01,\n",
       "         -6.0096e-01, -5.7525e-01,  9.9863e-01,  4.8118e-01,  9.7193e-01,\n",
       "         -9.9961e-01, -9.9971e-01, -3.6353e-02, -9.9998e-01,  9.8824e-01,\n",
       "          9.9988e-01, -2.6998e-01,  9.2465e-01, -2.7921e-01,  3.6133e-02,\n",
       "         -9.9816e-01, -1.0000e+00,  9.1931e-01,  9.9913e-01, -1.7193e-01,\n",
       "         -9.9842e-01,  2.9273e-02, -9.9935e-01,  2.1409e-02,  9.1144e-01,\n",
       "          9.9648e-01, -9.9892e-01,  9.8199e-01, -9.8576e-01,  6.1062e-02,\n",
       "          9.3752e-01, -1.0000e+00,  7.9285e-02, -9.9990e-01,  9.9909e-01,\n",
       "         -1.0000e+00,  7.2826e-01, -2.4072e-01,  4.2441e-02,  1.6747e-01,\n",
       "          2.6363e-01, -9.9996e-01,  4.0044e-02,  8.4598e-01,  9.7019e-01,\n",
       "         -2.7398e-01,  9.9913e-01, -2.5941e-01]], grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=(tensor([[[[4.3089e-01, 6.5030e-04, 1.7563e-04,  ..., 3.1788e-04,\n",
       "           2.7584e-03, 5.5912e-01],\n",
       "          [7.4552e-03, 5.5682e-02, 1.2652e-02,  ..., 1.9414e-02,\n",
       "           1.2198e-01, 8.1672e-03],\n",
       "          [1.3722e-02, 1.9581e-02, 2.6174e-02,  ..., 3.3219e-02,\n",
       "           5.0761e-02, 2.6728e-03],\n",
       "          ...,\n",
       "          [1.4699e-02, 2.3596e-02, 4.0991e-02,  ..., 1.1372e-01,\n",
       "           2.8370e-02, 3.8200e-03],\n",
       "          [2.8161e-02, 5.6331e-02, 2.4763e-02,  ..., 2.5546e-02,\n",
       "           1.9520e-01, 2.7509e-02],\n",
       "          [3.3683e-01, 1.2084e-03, 1.5142e-04,  ..., 4.3617e-04,\n",
       "           4.4971e-03, 6.5060e-01]],\n",
       "\n",
       "         [[9.9297e-01, 8.0111e-04, 4.3527e-04,  ..., 4.6843e-06,\n",
       "           3.7336e-04, 2.3445e-03],\n",
       "          [9.3689e-01, 8.1746e-04, 5.9399e-02,  ..., 7.7731e-08,\n",
       "           7.5183e-05, 3.8372e-05],\n",
       "          [7.9605e-01, 1.5971e-01, 1.1464e-03,  ..., 3.1289e-02,\n",
       "           9.7221e-07, 1.1116e-04],\n",
       "          ...,\n",
       "          [6.8265e-01, 1.0574e-06, 1.0840e-03,  ..., 1.2904e-02,\n",
       "           2.4528e-01, 1.3067e-02],\n",
       "          [1.6935e-01, 9.0690e-06, 8.6540e-09,  ..., 3.7023e-03,\n",
       "           2.3940e-04, 8.2653e-01],\n",
       "          [6.0089e-01, 5.8919e-06, 1.8668e-06,  ..., 2.1007e-05,\n",
       "           3.9469e-01, 1.8953e-03]],\n",
       "\n",
       "         [[1.4222e-01, 8.6248e-02, 7.4457e-02,  ..., 1.3768e-02,\n",
       "           8.5783e-02, 1.6739e-01],\n",
       "          [4.8764e-01, 2.4904e-01, 2.5053e-02,  ..., 5.6938e-03,\n",
       "           3.0092e-02, 8.1631e-02],\n",
       "          [4.9814e-01, 1.6525e-01, 1.3526e-01,  ..., 4.2821e-03,\n",
       "           2.5698e-02, 7.1425e-02],\n",
       "          ...,\n",
       "          [1.2187e-01, 2.1465e-02, 3.5355e-02,  ..., 5.1051e-02,\n",
       "           2.5356e-02, 2.1044e-02],\n",
       "          [2.3664e-02, 1.2365e-02, 6.2227e-03,  ..., 3.4331e-02,\n",
       "           1.0686e-01, 5.3162e-02],\n",
       "          [2.6328e-02, 1.8834e-02, 1.3541e-02,  ..., 7.0440e-02,\n",
       "           1.9966e-01, 1.1384e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[5.4704e-01, 1.2309e-02, 9.4632e-03,  ..., 1.7329e-02,\n",
       "           8.8011e-02, 7.3362e-02],\n",
       "          [7.1367e-02, 1.4932e-01, 6.5667e-03,  ..., 2.5484e-02,\n",
       "           1.3385e-02, 1.8851e-01],\n",
       "          [3.0673e-01, 8.0438e-03, 1.7958e-01,  ..., 3.7865e-02,\n",
       "           2.3608e-02, 2.6679e-02],\n",
       "          ...,\n",
       "          [4.8289e-01, 7.5115e-03, 5.8342e-03,  ..., 1.9299e-01,\n",
       "           5.6648e-03, 3.2446e-02],\n",
       "          [9.6835e-02, 4.5422e-02, 1.7317e-02,  ..., 2.8134e-03,\n",
       "           2.1018e-01, 2.6234e-01],\n",
       "          [2.7155e-01, 1.7651e-02, 2.0039e-02,  ..., 8.2587e-03,\n",
       "           1.9589e-02, 8.7222e-02]],\n",
       "\n",
       "         [[9.6126e-01, 3.6688e-03, 6.3329e-03,  ..., 9.1091e-04,\n",
       "           5.6716e-04, 2.2108e-03],\n",
       "          [2.5899e-02, 4.7893e-02, 6.6401e-01,  ..., 3.4505e-04,\n",
       "           1.6469e-04, 5.0955e-04],\n",
       "          [4.4722e-02, 1.5828e-02, 5.3308e-02,  ..., 9.4714e-03,\n",
       "           1.4727e-03, 8.8778e-04],\n",
       "          ...,\n",
       "          [3.9749e-03, 4.8590e-05, 5.8776e-05,  ..., 1.5819e-02,\n",
       "           9.0075e-01, 6.8755e-02],\n",
       "          [4.7980e-03, 1.5612e-05, 8.8189e-05,  ..., 3.6331e-03,\n",
       "           6.5676e-02, 9.1994e-01],\n",
       "          [9.9582e-01, 1.0015e-05, 7.9068e-06,  ..., 1.3258e-04,\n",
       "           1.9795e-04, 3.4296e-03]],\n",
       "\n",
       "         [[3.5710e-01, 3.1212e-02, 2.7187e-02,  ..., 1.5850e-02,\n",
       "           2.3904e-02, 2.6769e-01],\n",
       "          [5.3674e-01, 1.9249e-01, 4.6415e-02,  ..., 4.5836e-03,\n",
       "           7.2789e-04, 8.0773e-03],\n",
       "          [1.8892e-01, 6.7892e-01, 3.6296e-02,  ..., 9.1373e-04,\n",
       "           6.6342e-04, 3.5371e-04],\n",
       "          ...,\n",
       "          [1.6662e-01, 2.7339e-03, 1.4194e-02,  ..., 3.4975e-02,\n",
       "           4.0554e-02, 1.9072e-02],\n",
       "          [1.8751e-01, 1.0783e-03, 1.6259e-03,  ..., 5.3438e-01,\n",
       "           1.0636e-01, 3.1669e-02],\n",
       "          [8.5468e-02, 3.1283e-04, 1.6488e-04,  ..., 3.4406e-02,\n",
       "           3.6377e-01, 4.8954e-01]]]], grad_fn=<SoftmaxBackward0>), tensor([[[[3.9525e-01, 1.3421e-02, 1.1299e-02,  ..., 9.8875e-03,\n",
       "           4.4859e-02, 3.8343e-01],\n",
       "          [4.9135e-01, 3.7219e-03, 1.3817e-02,  ..., 2.4377e-05,\n",
       "           2.1153e-04, 4.7900e-01],\n",
       "          [2.3266e-01, 5.2158e-01, 8.6371e-03,  ..., 7.1894e-05,\n",
       "           2.3589e-04, 2.2415e-01],\n",
       "          ...,\n",
       "          [2.8889e-01, 2.3166e-06, 4.7677e-03,  ..., 1.0947e-03,\n",
       "           2.4382e-02, 2.8112e-01],\n",
       "          [3.8116e-01, 1.9177e-03, 5.3920e-05,  ..., 2.1376e-01,\n",
       "           1.0508e-02, 3.8429e-01],\n",
       "          [3.9690e-01, 1.2619e-02, 1.1037e-02,  ..., 9.8227e-03,\n",
       "           4.6273e-02, 3.8498e-01]],\n",
       "\n",
       "         [[4.6125e-01, 8.9720e-03, 6.2600e-03,  ..., 3.4655e-03,\n",
       "           5.5157e-03, 4.4760e-01],\n",
       "          [4.3322e-02, 5.7864e-02, 6.6572e-02,  ..., 3.5770e-02,\n",
       "           1.3470e-01, 4.3100e-02],\n",
       "          [7.5519e-02, 1.4910e-02, 1.9586e-02,  ..., 4.0082e-02,\n",
       "           4.4191e-02, 7.6616e-02],\n",
       "          ...,\n",
       "          [4.2278e-01, 7.3311e-03, 4.9257e-03,  ..., 5.3859e-03,\n",
       "           5.8101e-02, 4.2174e-01],\n",
       "          [1.3230e-01, 5.9843e-02, 4.3187e-02,  ..., 4.7405e-02,\n",
       "           1.7057e-01, 1.3201e-01],\n",
       "          [4.6348e-01, 8.4087e-03, 5.9312e-03,  ..., 3.3357e-03,\n",
       "           5.1639e-03, 4.5008e-01]],\n",
       "\n",
       "         [[4.7001e-01, 1.0573e-02, 1.8447e-03,  ..., 2.4122e-03,\n",
       "           3.5444e-03, 4.3583e-01],\n",
       "          [3.8380e-01, 1.7212e-01, 5.4854e-03,  ..., 1.7719e-03,\n",
       "           9.3378e-03, 3.8083e-01],\n",
       "          [4.1473e-01, 1.8340e-03, 1.3826e-01,  ..., 2.3240e-03,\n",
       "           2.6152e-03, 3.9817e-01],\n",
       "          ...,\n",
       "          [3.8941e-01, 1.0131e-03, 9.0744e-04,  ..., 1.7939e-01,\n",
       "           3.5301e-03, 3.8448e-01],\n",
       "          [4.4783e-01, 6.0890e-03, 1.0829e-03,  ..., 4.0180e-03,\n",
       "           3.2939e-02, 4.2611e-01],\n",
       "          [4.6927e-01, 1.0635e-02, 1.8916e-03,  ..., 2.4347e-03,\n",
       "           3.5464e-03, 4.3472e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[4.3141e-01, 1.2334e-02, 1.0794e-02,  ..., 1.0864e-02,\n",
       "           2.6469e-02, 4.0928e-01],\n",
       "          [2.0009e-01, 4.5459e-02, 5.0419e-02,  ..., 7.8068e-03,\n",
       "           2.2139e-02, 1.9649e-01],\n",
       "          [1.4156e-01, 6.5291e-03, 4.2017e-02,  ..., 2.4088e-03,\n",
       "           7.3729e-03, 1.4306e-01],\n",
       "          ...,\n",
       "          [4.3613e-01, 2.2316e-04, 1.0664e-04,  ..., 1.8523e-02,\n",
       "           7.4774e-02, 4.5602e-01],\n",
       "          [4.4684e-01, 2.3041e-02, 9.2652e-04,  ..., 3.9773e-03,\n",
       "           3.3996e-02, 4.4372e-01],\n",
       "          [4.3215e-01, 1.2201e-02, 1.0780e-02,  ..., 1.0637e-02,\n",
       "           2.5758e-02, 4.1023e-01]],\n",
       "\n",
       "         [[4.7319e-01, 6.7297e-03, 5.7346e-03,  ..., 1.5959e-03,\n",
       "           7.8881e-03, 4.5106e-01],\n",
       "          [2.6280e-01, 9.8015e-02, 4.6593e-02,  ..., 1.3810e-02,\n",
       "           5.7097e-02, 2.5219e-01],\n",
       "          [2.6257e-01, 1.0360e-01, 8.6239e-02,  ..., 6.1796e-03,\n",
       "           3.2455e-02, 2.5273e-01],\n",
       "          ...,\n",
       "          [1.8190e-01, 4.6143e-02, 1.6234e-02,  ..., 4.5692e-03,\n",
       "           2.4039e-02, 1.7677e-01],\n",
       "          [5.4079e-02, 2.2525e-01, 4.2667e-02,  ..., 1.4795e-02,\n",
       "           3.2931e-02, 5.3698e-02],\n",
       "          [4.7273e-01, 6.7120e-03, 5.7180e-03,  ..., 1.6430e-03,\n",
       "           7.8580e-03, 4.5104e-01]],\n",
       "\n",
       "         [[4.5055e-01, 6.7385e-03, 1.2161e-03,  ..., 1.7669e-03,\n",
       "           2.1556e-02, 4.3751e-01],\n",
       "          [1.6720e-01, 6.6583e-02, 8.4557e-02,  ..., 3.7972e-02,\n",
       "           3.6359e-02, 1.5880e-01],\n",
       "          [1.5845e-01, 7.6830e-02, 5.4815e-02,  ..., 1.5418e-02,\n",
       "           3.5167e-02, 1.5260e-01],\n",
       "          ...,\n",
       "          [2.3316e-01, 3.5316e-02, 1.5263e-02,  ..., 5.1532e-02,\n",
       "           3.1020e-02, 2.2871e-01],\n",
       "          [1.4683e-01, 8.6107e-02, 5.8166e-02,  ..., 2.4482e-02,\n",
       "           1.1256e-02, 1.4252e-01],\n",
       "          [4.4959e-01, 6.5266e-03, 1.1889e-03,  ..., 1.7966e-03,\n",
       "           2.2059e-02, 4.3682e-01]]]], grad_fn=<SoftmaxBackward0>), tensor([[[[3.4934e-01, 8.2671e-02, 1.6643e-02,  ..., 1.1102e-02,\n",
       "           2.6485e-02, 3.4493e-01],\n",
       "          [4.3374e-01, 4.8124e-02, 8.9626e-03,  ..., 9.8008e-04,\n",
       "           1.3410e-02, 4.2961e-01],\n",
       "          [4.3327e-01, 5.4973e-02, 2.4969e-02,  ..., 4.0510e-04,\n",
       "           6.7175e-03, 4.2772e-01],\n",
       "          ...,\n",
       "          [2.1684e-01, 3.0922e-02, 1.4562e-02,  ..., 5.9648e-03,\n",
       "           7.3811e-03, 2.1411e-01],\n",
       "          [3.1907e-01, 3.1823e-02, 1.1375e-02,  ..., 1.4320e-02,\n",
       "           1.5707e-02, 3.1442e-01],\n",
       "          [3.5004e-01, 8.1925e-02, 1.6499e-02,  ..., 1.1119e-02,\n",
       "           2.6375e-02, 3.4563e-01]],\n",
       "\n",
       "         [[3.1425e-02, 1.7820e-01, 4.6639e-02,  ..., 4.4611e-02,\n",
       "           1.1230e-01, 3.1185e-02],\n",
       "          [1.8387e-01, 2.7397e-02, 3.7845e-01,  ..., 3.2027e-03,\n",
       "           6.3338e-03, 1.8012e-01],\n",
       "          [3.4974e-01, 1.1333e-01, 2.9453e-03,  ..., 4.5086e-03,\n",
       "           1.8308e-03, 3.4268e-01],\n",
       "          ...,\n",
       "          [3.9081e-01, 1.3378e-03, 3.7011e-04,  ..., 6.4079e-02,\n",
       "           4.4083e-02, 3.8408e-01],\n",
       "          [3.3534e-02, 1.1859e-03, 8.2382e-04,  ..., 6.3592e-01,\n",
       "           4.6930e-03, 3.3151e-02],\n",
       "          [3.1484e-02, 1.7784e-01, 4.6761e-02,  ..., 4.4515e-02,\n",
       "           1.1203e-01, 3.1243e-02]],\n",
       "\n",
       "         [[3.8902e-01, 2.1187e-03, 2.9091e-04,  ..., 2.9854e-03,\n",
       "           1.3242e-01, 3.8604e-01],\n",
       "          [4.0436e-01, 2.9543e-02, 9.4288e-03,  ..., 2.2692e-02,\n",
       "           8.7854e-03, 3.9751e-01],\n",
       "          [4.6284e-01, 8.5778e-03, 9.4783e-03,  ..., 3.8582e-03,\n",
       "           5.8542e-03, 4.5328e-01],\n",
       "          ...,\n",
       "          [4.3780e-01, 4.0240e-03, 1.7832e-03,  ..., 1.8280e-02,\n",
       "           4.8342e-03, 4.3110e-01],\n",
       "          [4.1012e-01, 5.9702e-03, 1.4204e-03,  ..., 4.7182e-02,\n",
       "           9.0664e-03, 4.0564e-01],\n",
       "          [3.8899e-01, 2.1220e-03, 2.9205e-04,  ..., 2.9970e-03,\n",
       "           1.3239e-01, 3.8601e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[3.1487e-02, 1.5136e-01, 6.5136e-02,  ..., 7.0071e-02,\n",
       "           2.8096e-02, 3.1084e-02],\n",
       "          [2.7534e-01, 3.6371e-02, 5.9354e-02,  ..., 1.8950e-02,\n",
       "           8.4420e-03, 2.7177e-01],\n",
       "          [2.7473e-01, 2.0437e-02, 6.5583e-02,  ..., 7.1837e-03,\n",
       "           1.4813e-02, 2.7067e-01],\n",
       "          ...,\n",
       "          [4.7803e-01, 1.4663e-04, 8.7180e-05,  ..., 1.7476e-02,\n",
       "           9.9576e-03, 4.7454e-01],\n",
       "          [4.7710e-01, 1.0833e-03, 5.4202e-04,  ..., 8.4039e-03,\n",
       "           9.8991e-03, 4.7289e-01],\n",
       "          [3.1600e-02, 1.5183e-01, 6.5123e-02,  ..., 6.9772e-02,\n",
       "           2.8017e-02, 3.1197e-02]],\n",
       "\n",
       "         [[6.4375e-02, 6.0751e-02, 1.5233e-02,  ..., 7.4685e-02,\n",
       "           1.0933e-01, 6.4165e-02],\n",
       "          [4.6641e-01, 2.4157e-02, 1.0039e-02,  ..., 1.2133e-04,\n",
       "           1.0888e-03, 4.6226e-01],\n",
       "          [4.6089e-01, 3.5613e-02, 3.3354e-02,  ..., 5.2373e-05,\n",
       "           4.5769e-04, 4.5384e-01],\n",
       "          ...,\n",
       "          [2.3469e-01, 6.9376e-03, 5.2115e-03,  ..., 2.0260e-02,\n",
       "           1.1402e-02, 2.3149e-01],\n",
       "          [2.8253e-01, 6.0681e-03, 1.3066e-02,  ..., 3.7045e-02,\n",
       "           4.1166e-02, 2.7807e-01],\n",
       "          [6.4482e-02, 6.0763e-02, 1.5205e-02,  ..., 7.4939e-02,\n",
       "           1.0936e-01, 6.4272e-02]],\n",
       "\n",
       "         [[1.2559e-01, 9.1178e-02, 4.0390e-02,  ..., 4.5284e-02,\n",
       "           7.8997e-02, 1.2315e-01],\n",
       "          [2.8130e-01, 1.8601e-02, 3.3324e-01,  ..., 2.5145e-03,\n",
       "           2.4677e-03, 2.7748e-01],\n",
       "          [3.6672e-01, 1.8307e-02, 1.1438e-02,  ..., 1.9480e-02,\n",
       "           4.2728e-03, 3.6135e-01],\n",
       "          ...,\n",
       "          [4.3371e-01, 8.1696e-04, 6.9469e-04,  ..., 2.6522e-02,\n",
       "           4.7667e-02, 4.3024e-01],\n",
       "          [4.3669e-01, 3.4023e-03, 8.7842e-04,  ..., 3.3880e-02,\n",
       "           1.5571e-02, 4.3451e-01],\n",
       "          [1.2587e-01, 9.1099e-02, 4.0156e-02,  ..., 4.5080e-02,\n",
       "           7.8979e-02, 1.2343e-01]]]], grad_fn=<SoftmaxBackward0>)), cross_attentions=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(**inputs)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained('rbt3', output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.4675,  1.0141, -0.0058,  ...,  0.1654,  0.2695,  0.0843],\n",
       "         [ 0.4492,  0.0087, -0.2444,  ..., -0.2155, -0.4300, -0.0175],\n",
       "         [-0.2932, -0.0460, -0.8318,  ...,  0.3941, -0.0197, -0.1786],\n",
       "         ...,\n",
       "         [-0.0657, -0.5814, -0.7339,  ...,  0.7724, -0.1228, -0.3468],\n",
       "         [ 0.2979,  0.2610, -0.7817,  ..., -0.0129, -0.0135, -0.3109],\n",
       "         [ 0.4630,  1.0184, -0.0088,  ...,  0.1672,  0.2708,  0.0854]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-8.8071e-02, -9.3004e-01, -9.9997e-01, -9.4734e-01, -7.9155e-01,\n",
       "         -2.0181e-02,  1.8273e-01, -2.7196e-01,  9.8799e-01,  9.9717e-01,\n",
       "          1.1182e-01, -1.0000e+00, -1.8678e-01,  9.9874e-01, -9.9999e-01,\n",
       "          9.9983e-01,  7.8124e-01,  9.7588e-01, -9.9137e-01, -5.9165e-02,\n",
       "         -9.9753e-01, -9.5086e-02, -6.9507e-02,  9.8925e-01,  9.9832e-01,\n",
       "         -9.9527e-01, -9.9819e-01, -2.1769e-02, -9.4477e-01, -9.9989e-01,\n",
       "         -9.3475e-01, -9.9818e-01, -2.1449e-01,  2.7004e-01,  9.9808e-01,\n",
       "         -9.4182e-01, -1.6109e-01, -9.7537e-01, -7.5599e-01, -9.9699e-01,\n",
       "         -1.2927e-01,  9.7804e-01,  5.2309e-02,  9.9958e-01,  1.2419e-02,\n",
       "          1.6658e-01,  9.9983e-01,  9.9716e-01,  1.9914e-01, -9.9668e-01,\n",
       "          8.1591e-02, -2.9870e-01, -9.3792e-01,  9.8901e-01,  1.5361e-01,\n",
       "          1.1624e-01,  9.9592e-01, -9.9996e-01, -9.9900e-01,  9.9382e-01,\n",
       "         -9.9910e-01,  9.8430e-01,  9.6573e-01,  9.9854e-01, -9.4498e-01,\n",
       "          9.9985e-01,  9.9089e-01,  7.9200e-01, -1.4306e-01, -9.9999e-01,\n",
       "          2.4702e-01, -8.9185e-01, -9.9976e-01,  9.3676e-02, -1.0036e-01,\n",
       "         -9.9968e-01,  9.9629e-01, -1.2471e-01,  9.9857e-01,  4.0931e-01,\n",
       "         -9.9981e-01, -1.9416e-02, -1.4906e-01,  1.8277e-01,  9.8704e-01,\n",
       "          9.9987e-01, -1.2285e-01, -9.9208e-01, -2.3926e-01, -9.9944e-01,\n",
       "          1.6915e-03,  9.9618e-01,  9.9998e-01, -9.9539e-01,  9.9997e-01,\n",
       "         -7.3283e-01,  1.2526e-01, -1.2448e-01, -9.3294e-01,  9.8590e-01,\n",
       "         -7.1023e-02,  8.3970e-02,  9.9999e-01,  9.9978e-01, -8.6410e-01,\n",
       "         -9.9785e-01, -9.9804e-01,  9.9645e-01, -9.9893e-01,  5.8787e-02,\n",
       "          9.9996e-01,  9.8327e-01,  1.0000e+00,  9.9799e-01,  9.9996e-01,\n",
       "         -9.9994e-01, -3.0990e-01,  1.0044e-01, -9.9841e-01,  9.9905e-01,\n",
       "         -8.2349e-01,  3.4312e-01, -8.9581e-01, -2.2379e-01, -5.5650e-02,\n",
       "         -9.9997e-01,  5.6618e-02, -3.0611e-01, -9.9181e-01, -9.9626e-01,\n",
       "         -9.8099e-01, -9.9288e-01,  9.9508e-01, -5.2224e-01,  2.8148e-01,\n",
       "         -1.6422e-02,  8.8674e-02, -3.2508e-03, -9.9996e-01, -9.9875e-01,\n",
       "         -9.9956e-01,  9.9203e-01,  5.7787e-01,  9.6784e-01, -9.7570e-01,\n",
       "          9.9962e-01, -9.9941e-01,  9.9935e-01,  9.8858e-01, -1.5363e-01,\n",
       "         -9.7691e-01,  9.2552e-02, -9.9772e-01, -1.3584e-01,  2.3427e-01,\n",
       "          9.9145e-01,  9.7685e-01,  8.9901e-01, -9.8653e-01,  9.9969e-01,\n",
       "         -9.9759e-01,  8.9926e-01,  1.5320e-01,  9.9886e-01,  1.0000e+00,\n",
       "         -9.9998e-01,  8.2798e-02, -9.9998e-01, -4.5016e-01, -3.2107e-01,\n",
       "          9.9730e-01,  9.9433e-01,  9.8534e-01,  9.9951e-01, -7.9309e-01,\n",
       "         -9.9638e-01,  9.7760e-01, -9.9979e-01,  7.2347e-01,  9.9997e-01,\n",
       "          3.1689e-01,  7.9250e-01,  9.9964e-01, -8.4280e-01,  9.9381e-01,\n",
       "         -3.7860e-02, -2.2647e-01, -9.9239e-01, -1.5977e-01, -4.8639e-01,\n",
       "          9.7660e-01, -9.8467e-01, -7.0340e-02,  8.3486e-01,  3.2667e-02,\n",
       "         -1.4431e-01, -9.9940e-01, -9.9971e-01,  9.9932e-01,  9.9053e-01,\n",
       "          8.0377e-01, -1.9414e-01,  9.9999e-01,  7.7563e-01,  9.9994e-01,\n",
       "         -5.8700e-02,  4.6805e-01, -7.0372e-02,  9.9729e-01,  5.1740e-04,\n",
       "          9.3270e-01,  1.9047e-01,  9.9987e-01, -9.8058e-01, -9.9994e-01,\n",
       "         -1.4565e-01,  9.9458e-01, -1.6338e-01, -9.9166e-01, -4.5744e-01,\n",
       "         -2.2108e-01,  9.9951e-01,  9.8385e-02, -6.3032e-01,  9.9646e-01,\n",
       "         -9.9851e-01,  7.5357e-01, -9.9986e-01, -9.9508e-01,  9.9926e-01,\n",
       "         -3.1574e-01, -1.0000e+00,  9.3815e-01,  9.9971e-01, -3.0284e-01,\n",
       "          9.9652e-01,  1.2565e-01, -9.9833e-01, -1.1218e-01, -4.6638e-02,\n",
       "         -9.9999e-01, -9.5318e-01, -1.0000e+00, -9.2300e-02, -1.3641e-01,\n",
       "          7.4068e-01, -1.0000e+00, -3.9821e-02, -9.9966e-01,  9.9514e-01,\n",
       "          9.9957e-01,  3.1940e-02,  5.0626e-02,  9.9993e-01, -4.5387e-01,\n",
       "         -8.7332e-02, -9.1049e-01,  2.9119e-01, -1.2946e-01,  9.9162e-01,\n",
       "         -3.7584e-02,  9.9867e-01, -9.9935e-01,  8.8741e-02,  7.9190e-01,\n",
       "         -9.9980e-01,  1.2526e-01,  9.8314e-01, -1.6491e-01, -1.1348e-01,\n",
       "         -1.4073e-02, -1.1696e-01,  8.0826e-01,  9.9808e-01,  1.0000e+00,\n",
       "          9.9491e-01,  9.9987e-01,  9.9998e-01, -1.5214e-02, -9.9496e-01,\n",
       "         -8.7391e-01,  1.8854e-01, -1.0000e+00, -9.5821e-01, -9.9301e-01,\n",
       "          9.8423e-01,  1.7414e-01,  1.0000e+00, -1.0000e+00,  9.9988e-01,\n",
       "         -9.6826e-01, -9.7625e-02, -3.2991e-02,  1.9463e-01, -3.8552e-01,\n",
       "          7.4516e-02,  9.8880e-01, -2.8921e-02,  9.7957e-01,  9.8342e-01,\n",
       "         -8.2949e-02, -7.7110e-02,  4.5104e-01, -1.8621e-01,  9.8485e-01,\n",
       "         -9.5571e-01,  9.9584e-01, -1.0414e-01,  9.9834e-01,  1.3483e-01,\n",
       "         -1.0000e+00,  9.9647e-01, -9.9962e-01, -3.0141e-01, -9.9843e-01,\n",
       "         -9.9493e-01,  2.8375e-01, -9.9786e-01,  4.9427e-01,  9.6741e-01,\n",
       "          2.2739e-01,  3.1124e-01, -9.9994e-01, -9.7724e-01,  8.5400e-01,\n",
       "          9.9970e-01, -9.9873e-01,  9.8097e-01,  9.9191e-01, -9.9087e-01,\n",
       "         -5.5008e-03,  9.0940e-01, -9.9829e-01,  9.7055e-01, -9.9979e-01,\n",
       "          1.0196e-01,  9.9958e-01, -6.5265e-02, -9.9936e-01, -9.4583e-01,\n",
       "          5.0099e-02,  8.9025e-01,  3.2010e-02,  9.9999e-01, -1.1530e-01,\n",
       "         -2.3274e-01, -9.9979e-01, -9.6282e-01, -9.0899e-01, -1.9246e-02,\n",
       "          9.9771e-01, -9.9970e-01, -1.1685e-01,  9.9704e-01, -9.9986e-01,\n",
       "         -1.0356e-01,  2.3202e-02, -3.6690e-01, -8.7576e-02, -9.8700e-01,\n",
       "         -9.9988e-01, -9.9954e-01,  9.9992e-01,  1.4243e-01, -2.0091e-01,\n",
       "          9.9836e-01,  9.9953e-01,  9.9950e-01, -9.1757e-01,  9.6589e-01,\n",
       "          9.9901e-01,  2.7066e-01,  1.8866e-01, -9.8815e-01, -1.2738e-01,\n",
       "         -5.9037e-01, -9.8984e-01, -1.1867e-02,  7.4347e-01, -8.4613e-01,\n",
       "         -9.7816e-01,  9.9946e-01,  9.9762e-01,  1.0000e+00,  5.8232e-02,\n",
       "         -8.8397e-01,  9.1627e-01, -9.1926e-01, -9.9247e-01, -1.2903e-01,\n",
       "          9.9836e-01, -9.8969e-01,  1.2010e-02, -3.7793e-01, -6.5051e-01,\n",
       "          9.9364e-01, -9.9584e-01,  6.3865e-02, -9.9999e-01, -9.9950e-01,\n",
       "         -9.9995e-01,  9.9933e-01, -9.0197e-03, -5.9559e-02, -9.9953e-01,\n",
       "          1.0000e+00,  9.9706e-01, -9.7955e-01, -2.8554e-01,  9.9963e-01,\n",
       "         -6.7079e-03, -9.4057e-01, -9.9998e-01, -9.9938e-01,  9.5457e-01,\n",
       "         -7.7452e-02,  9.9998e-01,  9.6309e-01, -9.9907e-01,  9.4788e-01,\n",
       "          9.6763e-01,  3.4924e-01, -9.9744e-01, -9.7449e-01, -1.5411e-01,\n",
       "         -9.0921e-02, -3.6622e-02,  1.0172e-02,  3.1738e-01,  9.9996e-01,\n",
       "         -1.5066e-01,  5.8620e-02,  6.2757e-02,  9.9988e-01,  6.8090e-01,\n",
       "         -9.9748e-01,  1.9067e-01,  3.9341e-02, -9.9212e-01, -9.9846e-01,\n",
       "         -9.9935e-01, -4.3203e-02,  1.6124e-01, -8.3430e-02, -9.9412e-01,\n",
       "         -9.9463e-01, -9.9860e-01,  9.3141e-03, -9.9529e-01, -9.8976e-01,\n",
       "         -1.7478e-02, -9.8723e-01, -9.9952e-01,  9.9914e-01, -9.9894e-01,\n",
       "         -9.0015e-03,  8.4133e-01,  9.9834e-01, -9.9746e-01,  3.4091e-01,\n",
       "          9.8659e-01, -9.9328e-01, -1.4238e-01, -9.6182e-01,  1.0063e-01,\n",
       "         -8.3938e-01, -9.9997e-01, -3.3924e-02,  9.9979e-01,  9.9816e-01,\n",
       "          9.9434e-01,  9.3028e-01, -8.9911e-01,  8.0563e-01,  9.9660e-01,\n",
       "          9.9999e-01, -2.3115e-01, -1.1422e-02, -9.9999e-01, -5.5310e-01,\n",
       "          9.6172e-01,  2.1643e-02,  9.2545e-01, -9.9859e-01,  2.5975e-01,\n",
       "         -9.9391e-01, -9.0683e-02,  1.0000e+00,  9.9821e-01,  7.3000e-01,\n",
       "         -9.9997e-01, -1.2803e-01, -5.1382e-01,  1.7677e-01, -9.3963e-01,\n",
       "          3.7302e-02,  9.9991e-01, -5.2293e-01,  4.4432e-01, -9.9150e-01,\n",
       "         -9.9955e-01,  9.9998e-01, -9.9935e-01,  9.9998e-01,  9.5229e-01,\n",
       "         -9.9178e-01,  5.7289e-02, -9.9760e-01, -1.6557e-01, -2.5147e-01,\n",
       "         -3.1193e-02,  1.8665e-01, -1.0434e-03, -9.9999e-01, -2.2667e-02,\n",
       "          9.7866e-01, -5.3943e-02, -3.2156e-01, -9.8977e-01,  9.2062e-02,\n",
       "          9.9750e-01, -9.9868e-01, -9.9965e-01, -1.3570e-01, -9.5387e-02,\n",
       "         -2.6968e-01,  3.8256e-01,  3.9084e-02,  3.6458e-01, -9.8638e-01,\n",
       "          7.9993e-02,  8.9161e-01, -9.7619e-01,  6.6304e-01, -6.5672e-01,\n",
       "         -8.4421e-01,  2.3099e-01,  9.9985e-01,  9.9994e-01, -9.9951e-01,\n",
       "         -9.9970e-01, -6.8407e-01,  8.7859e-02,  2.2103e-01,  9.9694e-01,\n",
       "         -2.8486e-03, -9.9026e-01, -3.2628e-02, -5.6648e-03, -1.7556e-01,\n",
       "         -7.3369e-01,  9.9996e-01, -9.8143e-01,  9.9998e-01, -9.9996e-01,\n",
       "         -9.9331e-01,  1.1617e-01,  9.9980e-01, -9.9992e-01,  2.0703e-01,\n",
       "          9.9639e-01, -9.9902e-01, -1.0205e-01, -9.6450e-01,  7.7164e-01,\n",
       "          4.8999e-03, -1.2384e-01,  3.6418e-01, -9.9781e-01,  7.9844e-02,\n",
       "         -9.9939e-01,  7.6582e-01,  9.9512e-01, -9.9822e-01, -9.1079e-01,\n",
       "         -9.9931e-01,  1.0467e-01,  1.9892e-01, -9.9590e-01,  9.4951e-01,\n",
       "          9.9999e-01,  2.4779e-01,  8.9094e-01, -9.9934e-01, -9.8903e-02,\n",
       "         -1.8170e-01, -9.9065e-01,  4.8935e-02, -9.9976e-01,  9.4774e-01,\n",
       "         -9.7960e-01,  9.9832e-01, -9.9996e-01,  9.5190e-01,  9.6884e-01,\n",
       "         -1.5791e-01, -3.0540e-01, -1.5109e-01,  7.7108e-01, -9.9976e-01,\n",
       "         -2.9319e-01, -9.9571e-01, -9.9911e-01, -2.1519e-01,  9.9985e-01,\n",
       "          9.6715e-01,  3.8091e-02,  9.9904e-01, -8.9794e-01,  3.3504e-02,\n",
       "          2.9690e-01,  3.6775e-01,  1.0000e+00, -9.9828e-01, -9.9996e-01,\n",
       "          9.8442e-01, -9.9968e-01, -9.6095e-01,  9.9996e-01,  3.8869e-01,\n",
       "          9.8596e-01,  1.0915e-01, -9.9199e-01,  5.8883e-02,  8.9000e-02,\n",
       "          9.9921e-01, -2.8589e-01, -2.6844e-01,  9.9997e-01, -8.8987e-02,\n",
       "          1.8998e-01, -5.4699e-02,  9.9688e-01, -5.0047e-02, -1.4103e-01,\n",
       "          9.7825e-01, -5.7326e-01, -9.9036e-01, -9.9951e-01, -1.4324e-01,\n",
       "          3.6437e-02, -2.4226e-01, -7.5459e-03,  8.8353e-01,  9.9994e-01,\n",
       "         -9.9442e-01,  9.7623e-01, -1.0000e+00, -9.9871e-01, -7.5336e-02,\n",
       "         -4.4723e-02,  9.9894e-01,  7.9585e-03, -9.8725e-01,  1.0792e-01,\n",
       "         -9.8922e-01,  9.6006e-01, -9.9956e-01,  9.7469e-01,  1.3854e-01,\n",
       "          1.4058e-02,  9.9997e-01,  9.7590e-01, -3.7066e-02, -9.6998e-01,\n",
       "         -9.0025e-01, -2.9404e-02, -9.9886e-01,  9.9936e-01,  7.4335e-02,\n",
       "          6.8973e-02,  8.0578e-03,  1.8934e-01, -9.9980e-01, -7.4278e-01,\n",
       "          5.4462e-02,  9.9382e-01, -9.9970e-01,  9.9777e-01, -9.7081e-01,\n",
       "          9.9896e-01,  9.9809e-01,  9.9999e-01,  3.0664e-02,  9.3919e-01,\n",
       "         -9.9600e-01, -9.9707e-01,  9.4291e-01,  9.4834e-01,  9.9910e-01,\n",
       "          9.6940e-01,  9.9642e-01,  9.2325e-02, -9.9919e-01, -2.1892e-01,\n",
       "         -1.6882e-01, -1.6953e-02,  1.0317e-01, -7.3714e-01, -9.9995e-01,\n",
       "          9.9955e-01, -9.9989e-01, -9.9986e-01, -8.3051e-01, -9.9992e-01,\n",
       "          9.9118e-01, -1.6215e-01,  9.9693e-01,  9.0800e-01, -9.9647e-01,\n",
       "         -9.8904e-01, -8.6761e-02, -8.9584e-01, -9.9307e-01,  8.9126e-02,\n",
       "         -1.0000e+00,  4.0777e-03,  5.4882e-02, -7.5475e-01,  3.1377e-01,\n",
       "         -6.0096e-01, -5.7525e-01,  9.9863e-01,  4.8118e-01,  9.7193e-01,\n",
       "         -9.9961e-01, -9.9971e-01, -3.6353e-02, -9.9998e-01,  9.8824e-01,\n",
       "          9.9988e-01, -2.6998e-01,  9.2465e-01, -2.7921e-01,  3.6133e-02,\n",
       "         -9.9816e-01, -1.0000e+00,  9.1931e-01,  9.9913e-01, -1.7193e-01,\n",
       "         -9.9842e-01,  2.9273e-02, -9.9935e-01,  2.1409e-02,  9.1144e-01,\n",
       "          9.9648e-01, -9.9892e-01,  9.8199e-01, -9.8576e-01,  6.1062e-02,\n",
       "          9.3752e-01, -1.0000e+00,  7.9285e-02, -9.9990e-01,  9.9909e-01,\n",
       "         -1.0000e+00,  7.2826e-01, -2.4072e-01,  4.2441e-02,  1.6747e-01,\n",
       "          2.6363e-01, -9.9996e-01,  4.0044e-02,  8.4598e-01,  9.7019e-01,\n",
       "         -2.7398e-01,  9.9913e-01, -2.5941e-01]], grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=(tensor([[[[4.3089e-01, 6.5030e-04, 1.7563e-04,  ..., 3.1788e-04,\n",
       "           2.7584e-03, 5.5912e-01],\n",
       "          [7.4552e-03, 5.5682e-02, 1.2652e-02,  ..., 1.9414e-02,\n",
       "           1.2198e-01, 8.1672e-03],\n",
       "          [1.3722e-02, 1.9581e-02, 2.6174e-02,  ..., 3.3219e-02,\n",
       "           5.0761e-02, 2.6728e-03],\n",
       "          ...,\n",
       "          [1.4699e-02, 2.3596e-02, 4.0991e-02,  ..., 1.1372e-01,\n",
       "           2.8370e-02, 3.8200e-03],\n",
       "          [2.8161e-02, 5.6331e-02, 2.4763e-02,  ..., 2.5546e-02,\n",
       "           1.9520e-01, 2.7509e-02],\n",
       "          [3.3683e-01, 1.2084e-03, 1.5142e-04,  ..., 4.3617e-04,\n",
       "           4.4971e-03, 6.5060e-01]],\n",
       "\n",
       "         [[9.9297e-01, 8.0111e-04, 4.3527e-04,  ..., 4.6843e-06,\n",
       "           3.7336e-04, 2.3445e-03],\n",
       "          [9.3689e-01, 8.1746e-04, 5.9399e-02,  ..., 7.7731e-08,\n",
       "           7.5183e-05, 3.8372e-05],\n",
       "          [7.9605e-01, 1.5971e-01, 1.1464e-03,  ..., 3.1289e-02,\n",
       "           9.7221e-07, 1.1116e-04],\n",
       "          ...,\n",
       "          [6.8265e-01, 1.0574e-06, 1.0840e-03,  ..., 1.2904e-02,\n",
       "           2.4528e-01, 1.3067e-02],\n",
       "          [1.6935e-01, 9.0690e-06, 8.6540e-09,  ..., 3.7023e-03,\n",
       "           2.3940e-04, 8.2653e-01],\n",
       "          [6.0089e-01, 5.8919e-06, 1.8668e-06,  ..., 2.1007e-05,\n",
       "           3.9469e-01, 1.8953e-03]],\n",
       "\n",
       "         [[1.4222e-01, 8.6248e-02, 7.4457e-02,  ..., 1.3768e-02,\n",
       "           8.5783e-02, 1.6739e-01],\n",
       "          [4.8764e-01, 2.4904e-01, 2.5053e-02,  ..., 5.6938e-03,\n",
       "           3.0092e-02, 8.1631e-02],\n",
       "          [4.9814e-01, 1.6525e-01, 1.3526e-01,  ..., 4.2821e-03,\n",
       "           2.5698e-02, 7.1425e-02],\n",
       "          ...,\n",
       "          [1.2187e-01, 2.1465e-02, 3.5355e-02,  ..., 5.1051e-02,\n",
       "           2.5356e-02, 2.1044e-02],\n",
       "          [2.3664e-02, 1.2365e-02, 6.2227e-03,  ..., 3.4331e-02,\n",
       "           1.0686e-01, 5.3162e-02],\n",
       "          [2.6328e-02, 1.8834e-02, 1.3541e-02,  ..., 7.0440e-02,\n",
       "           1.9966e-01, 1.1384e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[5.4704e-01, 1.2309e-02, 9.4632e-03,  ..., 1.7329e-02,\n",
       "           8.8011e-02, 7.3362e-02],\n",
       "          [7.1367e-02, 1.4932e-01, 6.5667e-03,  ..., 2.5484e-02,\n",
       "           1.3385e-02, 1.8851e-01],\n",
       "          [3.0673e-01, 8.0438e-03, 1.7958e-01,  ..., 3.7865e-02,\n",
       "           2.3608e-02, 2.6679e-02],\n",
       "          ...,\n",
       "          [4.8289e-01, 7.5115e-03, 5.8342e-03,  ..., 1.9299e-01,\n",
       "           5.6648e-03, 3.2446e-02],\n",
       "          [9.6835e-02, 4.5422e-02, 1.7317e-02,  ..., 2.8134e-03,\n",
       "           2.1018e-01, 2.6234e-01],\n",
       "          [2.7155e-01, 1.7651e-02, 2.0039e-02,  ..., 8.2587e-03,\n",
       "           1.9589e-02, 8.7222e-02]],\n",
       "\n",
       "         [[9.6126e-01, 3.6688e-03, 6.3329e-03,  ..., 9.1091e-04,\n",
       "           5.6716e-04, 2.2108e-03],\n",
       "          [2.5899e-02, 4.7893e-02, 6.6401e-01,  ..., 3.4505e-04,\n",
       "           1.6469e-04, 5.0955e-04],\n",
       "          [4.4722e-02, 1.5828e-02, 5.3308e-02,  ..., 9.4714e-03,\n",
       "           1.4727e-03, 8.8778e-04],\n",
       "          ...,\n",
       "          [3.9749e-03, 4.8590e-05, 5.8776e-05,  ..., 1.5819e-02,\n",
       "           9.0075e-01, 6.8755e-02],\n",
       "          [4.7980e-03, 1.5612e-05, 8.8189e-05,  ..., 3.6331e-03,\n",
       "           6.5676e-02, 9.1994e-01],\n",
       "          [9.9582e-01, 1.0015e-05, 7.9068e-06,  ..., 1.3258e-04,\n",
       "           1.9795e-04, 3.4296e-03]],\n",
       "\n",
       "         [[3.5710e-01, 3.1212e-02, 2.7187e-02,  ..., 1.5850e-02,\n",
       "           2.3904e-02, 2.6769e-01],\n",
       "          [5.3674e-01, 1.9249e-01, 4.6415e-02,  ..., 4.5836e-03,\n",
       "           7.2789e-04, 8.0773e-03],\n",
       "          [1.8892e-01, 6.7892e-01, 3.6296e-02,  ..., 9.1373e-04,\n",
       "           6.6342e-04, 3.5371e-04],\n",
       "          ...,\n",
       "          [1.6662e-01, 2.7339e-03, 1.4194e-02,  ..., 3.4975e-02,\n",
       "           4.0554e-02, 1.9072e-02],\n",
       "          [1.8751e-01, 1.0783e-03, 1.6259e-03,  ..., 5.3438e-01,\n",
       "           1.0636e-01, 3.1669e-02],\n",
       "          [8.5468e-02, 3.1283e-04, 1.6488e-04,  ..., 3.4406e-02,\n",
       "           3.6377e-01, 4.8954e-01]]]], grad_fn=<SoftmaxBackward0>), tensor([[[[3.9525e-01, 1.3421e-02, 1.1299e-02,  ..., 9.8875e-03,\n",
       "           4.4859e-02, 3.8343e-01],\n",
       "          [4.9135e-01, 3.7219e-03, 1.3817e-02,  ..., 2.4377e-05,\n",
       "           2.1153e-04, 4.7900e-01],\n",
       "          [2.3266e-01, 5.2158e-01, 8.6371e-03,  ..., 7.1894e-05,\n",
       "           2.3589e-04, 2.2415e-01],\n",
       "          ...,\n",
       "          [2.8889e-01, 2.3166e-06, 4.7677e-03,  ..., 1.0947e-03,\n",
       "           2.4382e-02, 2.8112e-01],\n",
       "          [3.8116e-01, 1.9177e-03, 5.3920e-05,  ..., 2.1376e-01,\n",
       "           1.0508e-02, 3.8429e-01],\n",
       "          [3.9690e-01, 1.2619e-02, 1.1037e-02,  ..., 9.8227e-03,\n",
       "           4.6273e-02, 3.8498e-01]],\n",
       "\n",
       "         [[4.6125e-01, 8.9720e-03, 6.2600e-03,  ..., 3.4655e-03,\n",
       "           5.5157e-03, 4.4760e-01],\n",
       "          [4.3322e-02, 5.7864e-02, 6.6572e-02,  ..., 3.5770e-02,\n",
       "           1.3470e-01, 4.3100e-02],\n",
       "          [7.5519e-02, 1.4910e-02, 1.9586e-02,  ..., 4.0082e-02,\n",
       "           4.4191e-02, 7.6616e-02],\n",
       "          ...,\n",
       "          [4.2278e-01, 7.3311e-03, 4.9257e-03,  ..., 5.3859e-03,\n",
       "           5.8101e-02, 4.2174e-01],\n",
       "          [1.3230e-01, 5.9843e-02, 4.3187e-02,  ..., 4.7405e-02,\n",
       "           1.7057e-01, 1.3201e-01],\n",
       "          [4.6348e-01, 8.4087e-03, 5.9312e-03,  ..., 3.3357e-03,\n",
       "           5.1639e-03, 4.5008e-01]],\n",
       "\n",
       "         [[4.7001e-01, 1.0573e-02, 1.8447e-03,  ..., 2.4122e-03,\n",
       "           3.5444e-03, 4.3583e-01],\n",
       "          [3.8380e-01, 1.7212e-01, 5.4854e-03,  ..., 1.7719e-03,\n",
       "           9.3378e-03, 3.8083e-01],\n",
       "          [4.1473e-01, 1.8340e-03, 1.3826e-01,  ..., 2.3240e-03,\n",
       "           2.6152e-03, 3.9817e-01],\n",
       "          ...,\n",
       "          [3.8941e-01, 1.0131e-03, 9.0744e-04,  ..., 1.7939e-01,\n",
       "           3.5301e-03, 3.8448e-01],\n",
       "          [4.4783e-01, 6.0890e-03, 1.0829e-03,  ..., 4.0180e-03,\n",
       "           3.2939e-02, 4.2611e-01],\n",
       "          [4.6927e-01, 1.0635e-02, 1.8916e-03,  ..., 2.4347e-03,\n",
       "           3.5464e-03, 4.3472e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[4.3141e-01, 1.2334e-02, 1.0794e-02,  ..., 1.0864e-02,\n",
       "           2.6469e-02, 4.0928e-01],\n",
       "          [2.0009e-01, 4.5459e-02, 5.0419e-02,  ..., 7.8068e-03,\n",
       "           2.2139e-02, 1.9649e-01],\n",
       "          [1.4156e-01, 6.5291e-03, 4.2017e-02,  ..., 2.4088e-03,\n",
       "           7.3729e-03, 1.4306e-01],\n",
       "          ...,\n",
       "          [4.3613e-01, 2.2316e-04, 1.0664e-04,  ..., 1.8523e-02,\n",
       "           7.4774e-02, 4.5602e-01],\n",
       "          [4.4684e-01, 2.3041e-02, 9.2652e-04,  ..., 3.9773e-03,\n",
       "           3.3996e-02, 4.4372e-01],\n",
       "          [4.3215e-01, 1.2201e-02, 1.0780e-02,  ..., 1.0637e-02,\n",
       "           2.5758e-02, 4.1023e-01]],\n",
       "\n",
       "         [[4.7319e-01, 6.7297e-03, 5.7346e-03,  ..., 1.5959e-03,\n",
       "           7.8881e-03, 4.5106e-01],\n",
       "          [2.6280e-01, 9.8015e-02, 4.6593e-02,  ..., 1.3810e-02,\n",
       "           5.7097e-02, 2.5219e-01],\n",
       "          [2.6257e-01, 1.0360e-01, 8.6239e-02,  ..., 6.1796e-03,\n",
       "           3.2455e-02, 2.5273e-01],\n",
       "          ...,\n",
       "          [1.8190e-01, 4.6143e-02, 1.6234e-02,  ..., 4.5692e-03,\n",
       "           2.4039e-02, 1.7677e-01],\n",
       "          [5.4079e-02, 2.2525e-01, 4.2667e-02,  ..., 1.4795e-02,\n",
       "           3.2931e-02, 5.3698e-02],\n",
       "          [4.7273e-01, 6.7120e-03, 5.7180e-03,  ..., 1.6430e-03,\n",
       "           7.8580e-03, 4.5104e-01]],\n",
       "\n",
       "         [[4.5055e-01, 6.7385e-03, 1.2161e-03,  ..., 1.7669e-03,\n",
       "           2.1556e-02, 4.3751e-01],\n",
       "          [1.6720e-01, 6.6583e-02, 8.4557e-02,  ..., 3.7972e-02,\n",
       "           3.6359e-02, 1.5880e-01],\n",
       "          [1.5845e-01, 7.6830e-02, 5.4815e-02,  ..., 1.5418e-02,\n",
       "           3.5167e-02, 1.5260e-01],\n",
       "          ...,\n",
       "          [2.3316e-01, 3.5316e-02, 1.5263e-02,  ..., 5.1532e-02,\n",
       "           3.1020e-02, 2.2871e-01],\n",
       "          [1.4683e-01, 8.6107e-02, 5.8166e-02,  ..., 2.4482e-02,\n",
       "           1.1256e-02, 1.4252e-01],\n",
       "          [4.4959e-01, 6.5266e-03, 1.1889e-03,  ..., 1.7966e-03,\n",
       "           2.2059e-02, 4.3682e-01]]]], grad_fn=<SoftmaxBackward0>), tensor([[[[3.4934e-01, 8.2671e-02, 1.6643e-02,  ..., 1.1102e-02,\n",
       "           2.6485e-02, 3.4493e-01],\n",
       "          [4.3374e-01, 4.8124e-02, 8.9626e-03,  ..., 9.8008e-04,\n",
       "           1.3410e-02, 4.2961e-01],\n",
       "          [4.3327e-01, 5.4973e-02, 2.4969e-02,  ..., 4.0510e-04,\n",
       "           6.7175e-03, 4.2772e-01],\n",
       "          ...,\n",
       "          [2.1684e-01, 3.0922e-02, 1.4562e-02,  ..., 5.9648e-03,\n",
       "           7.3811e-03, 2.1411e-01],\n",
       "          [3.1907e-01, 3.1823e-02, 1.1375e-02,  ..., 1.4320e-02,\n",
       "           1.5707e-02, 3.1442e-01],\n",
       "          [3.5004e-01, 8.1925e-02, 1.6499e-02,  ..., 1.1119e-02,\n",
       "           2.6375e-02, 3.4563e-01]],\n",
       "\n",
       "         [[3.1425e-02, 1.7820e-01, 4.6639e-02,  ..., 4.4611e-02,\n",
       "           1.1230e-01, 3.1185e-02],\n",
       "          [1.8387e-01, 2.7397e-02, 3.7845e-01,  ..., 3.2027e-03,\n",
       "           6.3338e-03, 1.8012e-01],\n",
       "          [3.4974e-01, 1.1333e-01, 2.9453e-03,  ..., 4.5086e-03,\n",
       "           1.8308e-03, 3.4268e-01],\n",
       "          ...,\n",
       "          [3.9081e-01, 1.3378e-03, 3.7011e-04,  ..., 6.4079e-02,\n",
       "           4.4083e-02, 3.8408e-01],\n",
       "          [3.3534e-02, 1.1859e-03, 8.2382e-04,  ..., 6.3592e-01,\n",
       "           4.6930e-03, 3.3151e-02],\n",
       "          [3.1484e-02, 1.7784e-01, 4.6761e-02,  ..., 4.4515e-02,\n",
       "           1.1203e-01, 3.1243e-02]],\n",
       "\n",
       "         [[3.8902e-01, 2.1187e-03, 2.9091e-04,  ..., 2.9854e-03,\n",
       "           1.3242e-01, 3.8604e-01],\n",
       "          [4.0436e-01, 2.9543e-02, 9.4288e-03,  ..., 2.2692e-02,\n",
       "           8.7854e-03, 3.9751e-01],\n",
       "          [4.6284e-01, 8.5778e-03, 9.4783e-03,  ..., 3.8582e-03,\n",
       "           5.8542e-03, 4.5328e-01],\n",
       "          ...,\n",
       "          [4.3780e-01, 4.0240e-03, 1.7832e-03,  ..., 1.8280e-02,\n",
       "           4.8342e-03, 4.3110e-01],\n",
       "          [4.1012e-01, 5.9702e-03, 1.4204e-03,  ..., 4.7182e-02,\n",
       "           9.0664e-03, 4.0564e-01],\n",
       "          [3.8899e-01, 2.1220e-03, 2.9205e-04,  ..., 2.9970e-03,\n",
       "           1.3239e-01, 3.8601e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[3.1487e-02, 1.5136e-01, 6.5136e-02,  ..., 7.0071e-02,\n",
       "           2.8096e-02, 3.1084e-02],\n",
       "          [2.7534e-01, 3.6371e-02, 5.9354e-02,  ..., 1.8950e-02,\n",
       "           8.4420e-03, 2.7177e-01],\n",
       "          [2.7473e-01, 2.0437e-02, 6.5583e-02,  ..., 7.1837e-03,\n",
       "           1.4813e-02, 2.7067e-01],\n",
       "          ...,\n",
       "          [4.7803e-01, 1.4663e-04, 8.7180e-05,  ..., 1.7476e-02,\n",
       "           9.9576e-03, 4.7454e-01],\n",
       "          [4.7710e-01, 1.0833e-03, 5.4202e-04,  ..., 8.4039e-03,\n",
       "           9.8991e-03, 4.7289e-01],\n",
       "          [3.1600e-02, 1.5183e-01, 6.5123e-02,  ..., 6.9772e-02,\n",
       "           2.8017e-02, 3.1197e-02]],\n",
       "\n",
       "         [[6.4375e-02, 6.0751e-02, 1.5233e-02,  ..., 7.4685e-02,\n",
       "           1.0933e-01, 6.4165e-02],\n",
       "          [4.6641e-01, 2.4157e-02, 1.0039e-02,  ..., 1.2133e-04,\n",
       "           1.0888e-03, 4.6226e-01],\n",
       "          [4.6089e-01, 3.5613e-02, 3.3354e-02,  ..., 5.2373e-05,\n",
       "           4.5769e-04, 4.5384e-01],\n",
       "          ...,\n",
       "          [2.3469e-01, 6.9376e-03, 5.2115e-03,  ..., 2.0260e-02,\n",
       "           1.1402e-02, 2.3149e-01],\n",
       "          [2.8253e-01, 6.0681e-03, 1.3066e-02,  ..., 3.7045e-02,\n",
       "           4.1166e-02, 2.7807e-01],\n",
       "          [6.4482e-02, 6.0763e-02, 1.5205e-02,  ..., 7.4939e-02,\n",
       "           1.0936e-01, 6.4272e-02]],\n",
       "\n",
       "         [[1.2559e-01, 9.1178e-02, 4.0390e-02,  ..., 4.5284e-02,\n",
       "           7.8997e-02, 1.2315e-01],\n",
       "          [2.8130e-01, 1.8601e-02, 3.3324e-01,  ..., 2.5145e-03,\n",
       "           2.4677e-03, 2.7748e-01],\n",
       "          [3.6672e-01, 1.8307e-02, 1.1438e-02,  ..., 1.9480e-02,\n",
       "           4.2728e-03, 3.6135e-01],\n",
       "          ...,\n",
       "          [4.3371e-01, 8.1696e-04, 6.9469e-04,  ..., 2.6522e-02,\n",
       "           4.7667e-02, 4.3024e-01],\n",
       "          [4.3669e-01, 3.4023e-03, 8.7842e-04,  ..., 3.3880e-02,\n",
       "           1.5571e-02, 4.3451e-01],\n",
       "          [1.2587e-01, 9.1099e-02, 4.0156e-02,  ..., 4.5080e-02,\n",
       "           7.8979e-02, 1.2343e-01]]]], grad_fn=<SoftmaxBackward0>)), cross_attentions=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(**inputs)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 22, 768])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.last_hidden_state.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 带有Model Head的模型调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at rbt3 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-0.5768,  0.5654]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clz_model = AutoModelForSequenceClassification.from_pretrained('rbt3')\n",
    "clz_model(**tokenizer(sen, return_tensors='pt'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS224N",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
