{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline 任务类型 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bigorange/miniconda3/envs/CS224N/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/bigorange/miniconda3/envs/CS224N/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/bigorange/miniconda3/envs/CS224N/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers.pipelines import SUPPORTED_TASKS, Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio-classification: audio\n",
      "automatic-speech-recognition: multimodal\n",
      "text-to-audio: text\n",
      "feature-extraction: multimodal\n",
      "text-classification: text\n",
      "token-classification: text\n",
      "question-answering: text\n",
      "table-question-answering: text\n",
      "visual-question-answering: multimodal\n",
      "document-question-answering: multimodal\n",
      "fill-mask: text\n",
      "summarization: text\n",
      "translation: text\n",
      "text2text-generation: text\n",
      "text-generation: text\n",
      "zero-shot-classification: text\n",
      "zero-shot-image-classification: multimodal\n",
      "zero-shot-audio-classification: multimodal\n",
      "image-classification: image\n",
      "image-feature-extraction: image\n",
      "image-segmentation: multimodal\n",
      "image-to-text: multimodal\n",
      "object-detection: multimodal\n",
      "zero-shot-object-detection: multimodal\n",
      "depth-estimation: image\n",
      "video-classification: video\n",
      "mask-generation: multimodal\n",
      "image-to-image: image\n"
     ]
    }
   ],
   "source": [
    "for k, v in SUPPORTED_TASKS.items():\n",
    "    print(f\"{k}: {v['type']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pileline创建使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bigorange/miniconda3/envs/CS224N/lib/python3.9/site-packages/transformers/deepspeed.py:24: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "loading configuration file config.json from cache at /home/bigorange/.cache/huggingface/hub/models--distilbert--distilbert-base-uncased-finetuned-sst-2-english/snapshots/714eb0fa89d2f80546fda750413ed43d93601a13/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/bigorange/.cache/huggingface/hub/models--distilbert--distilbert-base-uncased-finetuned-sst-2-english/snapshots/714eb0fa89d2f80546fda750413ed43d93601a13/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/bigorange/.cache/huggingface/hub/models--distilbert--distilbert-base-uncased-finetuned-sst-2-english/snapshots/714eb0fa89d2f80546fda750413ed43d93601a13/model.safetensors\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert/distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file config.json from cache at /home/bigorange/.cache/huggingface/hub/models--distilbert--distilbert-base-uncased-finetuned-sst-2-english/snapshots/714eb0fa89d2f80546fda750413ed43d93601a13/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /home/bigorange/.cache/huggingface/hub/models--distilbert--distilbert-base-uncased-finetuned-sst-2-english/snapshots/714eb0fa89d2f80546fda750413ed43d93601a13/vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/bigorange/.cache/huggingface/hub/models--distilbert--distilbert-base-uncased-finetuned-sst-2-english/snapshots/714eb0fa89d2f80546fda750413ed43d93601a13/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/bigorange/.cache/huggingface/hub/models--distilbert--distilbert-base-uncased-finetuned-sst-2-english/snapshots/714eb0fa89d2f80546fda750413ed43d93601a13/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/bigorange/.cache/huggingface/hub/models--distilbert--distilbert-base-uncased-finetuned-sst-2-english/snapshots/714eb0fa89d2f80546fda750413ed43d93601a13/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline('text-classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998520612716675}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe('very good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-finetuned-dianping-chinese/snapshots/25faf1874b21e76db31ea9c396ccf2a0322e0071/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"uer/roberta-base-finetuned-dianping-chinese\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"negative (stars 1, 2 and 3)\",\n",
      "    \"1\": \"positive (stars 4 and 5)\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative (stars 1, 2 and 3)\": 0,\n",
      "    \"positive (stars 4 and 5)\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-finetuned-dianping-chinese/snapshots/25faf1874b21e76db31ea9c396ccf2a0322e0071/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"uer/roberta-base-finetuned-dianping-chinese\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"negative (stars 1, 2 and 3)\",\n",
      "    \"1\": \"positive (stars 4 and 5)\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative (stars 1, 2 and 3)\": 0,\n",
      "    \"positive (stars 4 and 5)\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-finetuned-dianping-chinese/snapshots/25faf1874b21e76db31ea9c396ccf2a0322e0071/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at uer/roberta-base-finetuned-dianping-chinese.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "loading configuration file config.json from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-finetuned-dianping-chinese/snapshots/25faf1874b21e76db31ea9c396ccf2a0322e0071/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"uer/roberta-base-finetuned-dianping-chinese\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"negative (stars 1, 2 and 3)\",\n",
      "    \"1\": \"positive (stars 4 and 5)\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative (stars 1, 2 and 3)\": 0,\n",
      "    \"positive (stars 4 and 5)\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-finetuned-dianping-chinese/snapshots/25faf1874b21e76db31ea9c396ccf2a0322e0071/vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-finetuned-dianping-chinese/snapshots/25faf1874b21e76db31ea9c396ccf2a0322e0071/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-finetuned-dianping-chinese/snapshots/25faf1874b21e76db31ea9c396ccf2a0322e0071/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-finetuned-dianping-chinese/snapshots/25faf1874b21e76db31ea9c396ccf2a0322e0071/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"uer/roberta-base-finetuned-dianping-chinese\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"negative (stars 1, 2 and 3)\",\n",
      "    \"1\": \"positive (stars 4 and 5)\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative (stars 1, 2 and 3)\": 0,\n",
      "    \"positive (stars 4 and 5)\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-finetuned-dianping-chinese/snapshots/25faf1874b21e76db31ea9c396ccf2a0322e0071/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"uer/roberta-base-finetuned-dianping-chinese\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"negative (stars 1, 2 and 3)\",\n",
      "    \"1\": \"positive (stars 4 and 5)\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative (stars 1, 2 and 3)\": 0,\n",
      "    \"positive (stars 4 and 5)\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline('text-classification', model='uer/roberta-base-finetuned-dianping-chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'negative (stars 1, 2 and 3)', 'score': 0.975609302520752}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe('我觉着不好')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-finetuned-dianping-chinese/snapshots/25faf1874b21e76db31ea9c396ccf2a0322e0071/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"uer/roberta-base-finetuned-dianping-chinese\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"negative (stars 1, 2 and 3)\",\n",
      "    \"1\": \"positive (stars 4 and 5)\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative (stars 1, 2 and 3)\": 0,\n",
      "    \"positive (stars 4 and 5)\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-finetuned-dianping-chinese/snapshots/25faf1874b21e76db31ea9c396ccf2a0322e0071/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at uer/roberta-base-finetuned-dianping-chinese.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "loading configuration file config.json from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-finetuned-dianping-chinese/snapshots/25faf1874b21e76db31ea9c396ccf2a0322e0071/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"uer/roberta-base-finetuned-dianping-chinese\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"negative (stars 1, 2 and 3)\",\n",
      "    \"1\": \"positive (stars 4 and 5)\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative (stars 1, 2 and 3)\": 0,\n",
      "    \"positive (stars 4 and 5)\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-finetuned-dianping-chinese/snapshots/25faf1874b21e76db31ea9c396ccf2a0322e0071/vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-finetuned-dianping-chinese/snapshots/25faf1874b21e76db31ea9c396ccf2a0322e0071/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-finetuned-dianping-chinese/snapshots/25faf1874b21e76db31ea9c396ccf2a0322e0071/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-finetuned-dianping-chinese/snapshots/25faf1874b21e76db31ea9c396ccf2a0322e0071/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"uer/roberta-base-finetuned-dianping-chinese\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"negative (stars 1, 2 and 3)\",\n",
      "    \"1\": \"positive (stars 4 and 5)\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative (stars 1, 2 and 3)\": 0,\n",
      "    \"positive (stars 4 and 5)\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-finetuned-dianping-chinese/snapshots/25faf1874b21e76db31ea9c396ccf2a0322e0071/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"uer/roberta-base-finetuned-dianping-chinese\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"negative (stars 1, 2 and 3)\",\n",
      "    \"1\": \"positive (stars 4 and 5)\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative (stars 1, 2 and 3)\": 0,\n",
      "    \"positive (stars 4 and 5)\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('uer/roberta-base-finetuned-dianping-chinese')\n",
    "tokenizer = AutoTokenizer.from_pretrained('uer/roberta-base-finetuned-dianping-chinese')\n",
    "pipe = pipeline('text-classification', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'negative (stars 1, 2 and 3)', 'score': 0.9922099113464355}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe('不好')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.035027492046356204\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "times = []\n",
    "for i in range(100):\n",
    "    torch.cuda.synchronize()\n",
    "    start = time.time()\n",
    "    pipe('不好')\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    times.append(end - start)\n",
    "print(sum(times) / len(times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-finetuned-dianping-chinese/snapshots/25faf1874b21e76db31ea9c396ccf2a0322e0071/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"uer/roberta-base-finetuned-dianping-chinese\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"negative (stars 1, 2 and 3)\",\n",
      "    \"1\": \"positive (stars 4 and 5)\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative (stars 1, 2 and 3)\": 0,\n",
      "    \"positive (stars 4 and 5)\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-finetuned-dianping-chinese/snapshots/25faf1874b21e76db31ea9c396ccf2a0322e0071/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"uer/roberta-base-finetuned-dianping-chinese\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"negative (stars 1, 2 and 3)\",\n",
      "    \"1\": \"positive (stars 4 and 5)\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative (stars 1, 2 and 3)\": 0,\n",
      "    \"positive (stars 4 and 5)\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-finetuned-dianping-chinese/snapshots/25faf1874b21e76db31ea9c396ccf2a0322e0071/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at uer/roberta-base-finetuned-dianping-chinese.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "loading configuration file config.json from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-finetuned-dianping-chinese/snapshots/25faf1874b21e76db31ea9c396ccf2a0322e0071/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"uer/roberta-base-finetuned-dianping-chinese\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"negative (stars 1, 2 and 3)\",\n",
      "    \"1\": \"positive (stars 4 and 5)\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative (stars 1, 2 and 3)\": 0,\n",
      "    \"positive (stars 4 and 5)\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-finetuned-dianping-chinese/snapshots/25faf1874b21e76db31ea9c396ccf2a0322e0071/vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-finetuned-dianping-chinese/snapshots/25faf1874b21e76db31ea9c396ccf2a0322e0071/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-finetuned-dianping-chinese/snapshots/25faf1874b21e76db31ea9c396ccf2a0322e0071/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-finetuned-dianping-chinese/snapshots/25faf1874b21e76db31ea9c396ccf2a0322e0071/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"uer/roberta-base-finetuned-dianping-chinese\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"negative (stars 1, 2 and 3)\",\n",
      "    \"1\": \"positive (stars 4 and 5)\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative (stars 1, 2 and 3)\": 0,\n",
      "    \"positive (stars 4 and 5)\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-finetuned-dianping-chinese/snapshots/25faf1874b21e76db31ea9c396ccf2a0322e0071/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"uer/roberta-base-finetuned-dianping-chinese\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"negative (stars 1, 2 and 3)\",\n",
      "    \"1\": \"positive (stars 4 and 5)\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative (stars 1, 2 and 3)\": 0,\n",
      "    \"positive (stars 4 and 5)\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline('text-classification', model='uer/roberta-base-finetuned-dianping-chinese', device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011890926361083985\n"
     ]
    }
   ],
   "source": [
    "times = []\n",
    "for i in range(100):\n",
    "    torch.cuda.synchronize()\n",
    "    start = time.time()\n",
    "    pipe('不好')\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    times.append(end - start)\n",
    "print(sum(times) / len(times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-chinese-extractive-qa/snapshots/9b02143727b9c4655d18b43a69fc39d5eb3ddd53/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"uer/roberta-base-chinese-extractive-qa\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-chinese-extractive-qa/snapshots/9b02143727b9c4655d18b43a69fc39d5eb3ddd53/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"uer/roberta-base-chinese-extractive-qa\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-chinese-extractive-qa/snapshots/9b02143727b9c4655d18b43a69fc39d5eb3ddd53/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForQuestionAnswering.\n",
      "\n",
      "All the weights of BertForQuestionAnswering were initialized from the model checkpoint at uer/roberta-base-chinese-extractive-qa.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n",
      "loading configuration file config.json from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-chinese-extractive-qa/snapshots/9b02143727b9c4655d18b43a69fc39d5eb3ddd53/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"uer/roberta-base-chinese-extractive-qa\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-chinese-extractive-qa/snapshots/9b02143727b9c4655d18b43a69fc39d5eb3ddd53/vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-chinese-extractive-qa/snapshots/9b02143727b9c4655d18b43a69fc39d5eb3ddd53/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-chinese-extractive-qa/snapshots/9b02143727b9c4655d18b43a69fc39d5eb3ddd53/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-chinese-extractive-qa/snapshots/9b02143727b9c4655d18b43a69fc39d5eb3ddd53/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"uer/roberta-base-chinese-extractive-qa\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-chinese-extractive-qa/snapshots/9b02143727b9c4655d18b43a69fc39d5eb3ddd53/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"uer/roberta-base-chinese-extractive-qa\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "qa_pipe = pipeline('question-answering', model='uer/roberta-base-chinese-extractive-qa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.question_answering.QuestionAnsweringPipeline at 0x7f3fe84f0f70>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 5.1604922191472724e-05, 'start': 0, 'end': 2, 'answer': '曾洁'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_pipe(question='谁是臭女人？', context='曾洁对男朋友很好', max_answer_len=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/bigorange/.cache/huggingface/hub/models--google--owlvit-base-patch32/snapshots/cbc355fb364588351c5d51c7f74465e8e7ec6f72/config.json\n",
      "text_config is None. Initializing the OwlViTTextConfig with default values.\n",
      "vision_config is None. initializing the OwlViTVisionConfig with default values.\n",
      "Model config OwlViTConfig {\n",
      "  \"_name_or_path\": \"google/owlvit-base-patch32\",\n",
      "  \"architectures\": [\n",
      "    \"OwlViTForObjectDetection\"\n",
      "  ],\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"logit_scale_init_value\": 2.6592,\n",
      "  \"model_type\": \"owlvit\",\n",
      "  \"projection_dim\": 512,\n",
      "  \"text_config\": {\n",
      "    \"bos_token_id\": 0,\n",
      "    \"dropout\": 0.0,\n",
      "    \"eos_token_id\": 2,\n",
      "    \"max_length\": 16,\n",
      "    \"model_type\": \"owlvit_text_model\",\n",
      "    \"pad_token_id\": 1\n",
      "  },\n",
      "  \"text_config_dict\": null,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"vision_config\": {\n",
      "    \"dropout\": 0.0,\n",
      "    \"model_type\": \"owlvit_vision_model\"\n",
      "  },\n",
      "  \"vision_config_dict\": null\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/bigorange/.cache/huggingface/hub/models--google--owlvit-base-patch32/snapshots/cbc355fb364588351c5d51c7f74465e8e7ec6f72/config.json\n",
      "text_config is None. Initializing the OwlViTTextConfig with default values.\n",
      "vision_config is None. initializing the OwlViTVisionConfig with default values.\n",
      "Model config OwlViTConfig {\n",
      "  \"_name_or_path\": \"google/owlvit-base-patch32\",\n",
      "  \"architectures\": [\n",
      "    \"OwlViTForObjectDetection\"\n",
      "  ],\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"logit_scale_init_value\": 2.6592,\n",
      "  \"model_type\": \"owlvit\",\n",
      "  \"projection_dim\": 512,\n",
      "  \"text_config\": {\n",
      "    \"bos_token_id\": 0,\n",
      "    \"dropout\": 0.0,\n",
      "    \"eos_token_id\": 2,\n",
      "    \"max_length\": 16,\n",
      "    \"model_type\": \"owlvit_text_model\",\n",
      "    \"pad_token_id\": 1\n",
      "  },\n",
      "  \"text_config_dict\": null,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"vision_config\": {\n",
      "    \"dropout\": 0.0,\n",
      "    \"model_type\": \"owlvit_vision_model\"\n",
      "  },\n",
      "  \"vision_config_dict\": null\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/bigorange/.cache/huggingface/hub/models--google--owlvit-base-patch32/snapshots/cbc355fb364588351c5d51c7f74465e8e7ec6f72/model.safetensors\n",
      "All model checkpoint weights were used when initializing OwlViTForObjectDetection.\n",
      "\n",
      "All the weights of OwlViTForObjectDetection were initialized from the model checkpoint at google/owlvit-base-patch32.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use OwlViTForObjectDetection for predictions without further training.\n",
      "loading file vocab.json from cache at /home/bigorange/.cache/huggingface/hub/models--google--owlvit-base-patch32/snapshots/cbc355fb364588351c5d51c7f74465e8e7ec6f72/vocab.json\n",
      "loading file merges.txt from cache at /home/bigorange/.cache/huggingface/hub/models--google--owlvit-base-patch32/snapshots/cbc355fb364588351c5d51c7f74465e8e7ec6f72/merges.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /home/bigorange/.cache/huggingface/hub/models--google--owlvit-base-patch32/snapshots/cbc355fb364588351c5d51c7f74465e8e7ec6f72/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /home/bigorange/.cache/huggingface/hub/models--google--owlvit-base-patch32/snapshots/cbc355fb364588351c5d51c7f74465e8e7ec6f72/tokenizer_config.json\n",
      "ftfy or spacy is not installed using custom BasicTokenizer instead of ftfy.\n",
      "loading configuration file preprocessor_config.json from cache at /home/bigorange/.cache/huggingface/hub/models--google--owlvit-base-patch32/snapshots/cbc355fb364588351c5d51c7f74465e8e7ec6f72/preprocessor_config.json\n",
      "size should be a dictionary on of the following set of keys: ({'height', 'width'}, {'shortest_edge'}, {'shortest_edge', 'longest_edge'}, {'longest_edge'}, {'max_width', 'max_height'}), got [768, 768]. Converted to {'height': 768, 'width': 768}.\n",
      "size should be a dictionary on of the following set of keys: ({'height', 'width'}, {'shortest_edge'}, {'shortest_edge', 'longest_edge'}, {'longest_edge'}, {'max_width', 'max_height'}), got 768. Converted to {'height': 768, 'width': 768}.\n",
      "Image processor OwlViTImageProcessor {\n",
      "  \"crop_size\": {\n",
      "    \"height\": 768,\n",
      "    \"width\": 768\n",
      "  },\n",
      "  \"do_center_crop\": false,\n",
      "  \"do_convert_rgb\": true,\n",
      "  \"do_normalize\": true,\n",
      "  \"do_rescale\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"image_mean\": [\n",
      "    0.48145466,\n",
      "    0.4578275,\n",
      "    0.40821073\n",
      "  ],\n",
      "  \"image_processor_type\": \"OwlViTImageProcessor\",\n",
      "  \"image_std\": [\n",
      "    0.26862954,\n",
      "    0.26130258,\n",
      "    0.27577711\n",
      "  ],\n",
      "  \"processor_class\": \"OwlViTProcessor\",\n",
      "  \"resample\": 3,\n",
      "  \"rescale_factor\": 0.00392156862745098,\n",
      "  \"size\": {\n",
      "    \"height\": 768,\n",
      "    \"width\": 768\n",
      "  }\n",
      "}\n",
      "\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = 'google/owlvit-base-patch32'\n",
    "dector = pipeline(model = checkpoint, task='zero-shot-object-detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import *\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-finetuned-dianping-chinese/snapshots/25faf1874b21e76db31ea9c396ccf2a0322e0071/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"uer/roberta-base-finetuned-dianping-chinese\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"negative (stars 1, 2 and 3)\",\n",
      "    \"1\": \"positive (stars 4 and 5)\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative (stars 1, 2 and 3)\": 0,\n",
      "    \"positive (stars 4 and 5)\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-finetuned-dianping-chinese/snapshots/25faf1874b21e76db31ea9c396ccf2a0322e0071/vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-finetuned-dianping-chinese/snapshots/25faf1874b21e76db31ea9c396ccf2a0322e0071/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-finetuned-dianping-chinese/snapshots/25faf1874b21e76db31ea9c396ccf2a0322e0071/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-finetuned-dianping-chinese/snapshots/25faf1874b21e76db31ea9c396ccf2a0322e0071/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"uer/roberta-base-finetuned-dianping-chinese\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"negative (stars 1, 2 and 3)\",\n",
      "    \"1\": \"positive (stars 4 and 5)\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative (stars 1, 2 and 3)\": 0,\n",
      "    \"positive (stars 4 and 5)\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-finetuned-dianping-chinese/snapshots/25faf1874b21e76db31ea9c396ccf2a0322e0071/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"uer/roberta-base-finetuned-dianping-chinese\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"negative (stars 1, 2 and 3)\",\n",
      "    \"1\": \"positive (stars 4 and 5)\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative (stars 1, 2 and 3)\": 0,\n",
      "    \"positive (stars 4 and 5)\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-finetuned-dianping-chinese/snapshots/25faf1874b21e76db31ea9c396ccf2a0322e0071/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"uer/roberta-base-finetuned-dianping-chinese\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"negative (stars 1, 2 and 3)\",\n",
      "    \"1\": \"positive (stars 4 and 5)\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative (stars 1, 2 and 3)\": 0,\n",
      "    \"positive (stars 4 and 5)\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-finetuned-dianping-chinese/snapshots/25faf1874b21e76db31ea9c396ccf2a0322e0071/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at uer/roberta-base-finetuned-dianping-chinese.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('uer/roberta-base-finetuned-dianping-chinese')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('uer/roberta-base-finetuned-dianping-chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 3295, 3815, 3221, 5634, 1957,  782,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = '曾洁是臭女人'\n",
    "inputs = tokenizer(input_text, return_tensors='pt')\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[ 0.9595, -1.0887]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = model(**inputs)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8858, 0.1142]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = res.logits\n",
    "logits = torch.softmax(logits, dim=1)\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = torch.argmax(logits).item()\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'negative (stars 1, 2 and 3)', 1: 'positive (stars 4 and 5)'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative (stars 1, 2 and 3)'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.config.id2label.get(pred)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = '我欲乘风'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-finetuned-dianping-chinese/snapshots/25faf1874b21e76db31ea9c396ccf2a0322e0071/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"uer/roberta-base-finetuned-dianping-chinese\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"negative (stars 1, 2 and 3)\",\n",
      "    \"1\": \"positive (stars 4 and 5)\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative (stars 1, 2 and 3)\": 0,\n",
      "    \"positive (stars 4 and 5)\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-finetuned-dianping-chinese/snapshots/25faf1874b21e76db31ea9c396ccf2a0322e0071/vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-finetuned-dianping-chinese/snapshots/25faf1874b21e76db31ea9c396ccf2a0322e0071/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-finetuned-dianping-chinese/snapshots/25faf1874b21e76db31ea9c396ccf2a0322e0071/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-finetuned-dianping-chinese/snapshots/25faf1874b21e76db31ea9c396ccf2a0322e0071/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"uer/roberta-base-finetuned-dianping-chinese\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"negative (stars 1, 2 and 3)\",\n",
      "    \"1\": \"positive (stars 4 and 5)\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative (stars 1, 2 and 3)\": 0,\n",
      "    \"positive (stars 4 and 5)\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/bigorange/.cache/huggingface/hub/models--uer--roberta-base-finetuned-dianping-chinese/snapshots/25faf1874b21e76db31ea9c396ccf2a0322e0071/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"uer/roberta-base-finetuned-dianping-chinese\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"negative (stars 1, 2 and 3)\",\n",
      "    \"1\": \"positive (stars 4 and 5)\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative (stars 1, 2 and 3)\": 0,\n",
      "    \"positive (stars 4 and 5)\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('uer/roberta-base-finetuned-dianping-chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in ../roberta_tokenizer/tokenizer_config.json\n",
      "Special tokens file saved in ../roberta_tokenizer/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('../roberta_tokenizer/tokenizer_config.json',\n",
       " '../roberta_tokenizer/special_tokens_map.json',\n",
       " '../roberta_tokenizer/vocab.txt',\n",
       " '../roberta_tokenizer/added_tokens.json',\n",
       " '../roberta_tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained('../roberta_tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='../roberta_tokenizer', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('../roberta_tokenizer')\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'史': 1380,\n",
       " '##落': 18919,\n",
       " '嘔': 1653,\n",
       " '陶': 7378,\n",
       " '##睛': 17771,\n",
       " 'loading': 10878,\n",
       " '燻': 4252,\n",
       " '##貼': 19585,\n",
       " '悩': 2645,\n",
       " '##之': 13779,\n",
       " '法': 3791,\n",
       " '獻': 4368,\n",
       " '##猶': 17405,\n",
       " '[unused61]': 61,\n",
       " '##蟠': 19155,\n",
       " 'before': 10735,\n",
       " '暮': 3272,\n",
       " '##盪': 17736,\n",
       " 'loftpermalink': 10056,\n",
       " '悠': 2641,\n",
       " '佩': 877,\n",
       " '诺': 6437,\n",
       " '唉': 1536,\n",
       " '##穴': 18011,\n",
       " '863': 12874,\n",
       " '卷': 1318,\n",
       " '笺': 5020,\n",
       " '##茶': 18820,\n",
       " '孛': 2103,\n",
       " 'admin': 8843,\n",
       " 'しの': 10270,\n",
       " '##赭': 19680,\n",
       " 'cool1': 12032,\n",
       " '宛': 2138,\n",
       " '崽': 2312,\n",
       " '絞': 5180,\n",
       " '##凡': 14184,\n",
       " '##嬸': 15147,\n",
       " '##棵': 16541,\n",
       " '90': 8192,\n",
       " 'it': 8233,\n",
       " 'オ': 597,\n",
       " '##より': 10190,\n",
       " '厨': 1337,\n",
       " '##86': 9219,\n",
       " '##ッフ': 10023,\n",
       " '##云': 13813,\n",
       " '##沦': 16827,\n",
       " '##莽': 18875,\n",
       " '1200': 8552,\n",
       " '2765': 9513,\n",
       " '宣': 2146,\n",
       " '钱': 7178,\n",
       " '迸': 6838,\n",
       " '131': 9403,\n",
       " '##娣': 15085,\n",
       " '平': 2398,\n",
       " '##廁': 15495,\n",
       " 'bar': 9054,\n",
       " '馆': 7667,\n",
       " '丞': 693,\n",
       " '##尷': 15277,\n",
       " '馏': 7671,\n",
       " '锺': 7247,\n",
       " '鵜': 7865,\n",
       " '##sse': 12754,\n",
       " '##囧': 14790,\n",
       " '1m': 12103,\n",
       " 'fox': 10872,\n",
       " 'nbsp': 8400,\n",
       " '弄': 2462,\n",
       " '迹': 6839,\n",
       " '##蟻': 19159,\n",
       " '##园': 14793,\n",
       " '##挲': 15978,\n",
       " 'think': 12553,\n",
       " '6gb': 12324,\n",
       " '嶽': 2329,\n",
       " '[unused34]': 34,\n",
       " '##鳕': 20904,\n",
       " '##羣': 18464,\n",
       " '##額': 20597,\n",
       " 'zip': 10947,\n",
       " '尹': 2222,\n",
       " 'angelababy': 10643,\n",
       " '##ard': 9345,\n",
       " '##缅': 18404,\n",
       " '口': 1366,\n",
       " '1895': 10794,\n",
       " 'eq': 11601,\n",
       " '##浇': 16899,\n",
       " '機': 3582,\n",
       " '衹': 6142,\n",
       " '##stone': 12795,\n",
       " 'う': 537,\n",
       " 'nick': 11243,\n",
       " '镳': 7267,\n",
       " '##え': 11661,\n",
       " '曖': 3281,\n",
       " '##迄': 19869,\n",
       " '##圧': 14818,\n",
       " '##焖': 17243,\n",
       " '##驢': 20771,\n",
       " '產': 4496,\n",
       " '##thing': 12012,\n",
       " '##tant': 12028,\n",
       " '##ョ': 13699,\n",
       " '绾': 5343,\n",
       " '##萵': 18916,\n",
       " '鬼': 7787,\n",
       " '滞': 4005,\n",
       " 'step3': 9434,\n",
       " '##烘': 17224,\n",
       " '伽': 850,\n",
       " '千': 1283,\n",
       " '##怕': 15643,\n",
       " '研': 4777,\n",
       " '蟆': 6093,\n",
       " '##丫': 13760,\n",
       " '850': 10205,\n",
       " '##鈾': 20110,\n",
       " 'tower': 11102,\n",
       " '✨': 501,\n",
       " '##瘘': 17657,\n",
       " '##壟': 14947,\n",
       " '2010': 8166,\n",
       " '厂': 1322,\n",
       " '擺': 3099,\n",
       " '埵': 1821,\n",
       " '##阜': 20395,\n",
       " '扰': 2817,\n",
       " '##姣': 15061,\n",
       " '##羟': 18462,\n",
       " '##窺': 18040,\n",
       " 'mb': 9499,\n",
       " '玩': 4381,\n",
       " '##ˊ': 13373,\n",
       " '##恚': 15668,\n",
       " '##缘': 18414,\n",
       " '##假': 14026,\n",
       " '##きます': 12506,\n",
       " 'swiss': 11503,\n",
       " '低': 856,\n",
       " '##亮': 13835,\n",
       " '##信': 13985,\n",
       " '##婧': 15102,\n",
       " '叶': 1383,\n",
       " '##hi': 8963,\n",
       " '015': 13220,\n",
       " '棘': 3475,\n",
       " '近': 6818,\n",
       " '囑': 1720,\n",
       " '媒': 2054,\n",
       " '绫': 5329,\n",
       " '橢': 3584,\n",
       " 'ᅪ': 312,\n",
       " '一': 671,\n",
       " '##流': 16894,\n",
       " '##窪': 18037,\n",
       " '负': 6566,\n",
       " '##竭': 18055,\n",
       " '##胍': 18578,\n",
       " '随': 7390,\n",
       " 'ng': 8885,\n",
       " '##◆': 10497,\n",
       " '##滁': 17048,\n",
       " 'months': 10195,\n",
       " '沾': 3783,\n",
       " '芾': 5716,\n",
       " '鹳': 7917,\n",
       " '滙': 4002,\n",
       " '##瘢': 17662,\n",
       " '醞': 7012,\n",
       " '##jie': 12732,\n",
       " '望': 3307,\n",
       " '##怀': 15634,\n",
       " '##坍': 14831,\n",
       " '##許': 19315,\n",
       " 'bing': 12960,\n",
       " '湯': 3966,\n",
       " '衣': 6132,\n",
       " '##014': 11365,\n",
       " '##沏': 16815,\n",
       " '東': 3346,\n",
       " '屿': 2257,\n",
       " '##aine': 12554,\n",
       " '##zen': 10549,\n",
       " '##牠': 17341,\n",
       " 'les': 10133,\n",
       " '砷': 4789,\n",
       " '铭': 7208,\n",
       " '##科': 17963,\n",
       " '辟': 6792,\n",
       " '##2c': 11935,\n",
       " '##rade': 10287,\n",
       " '##玄': 17428,\n",
       " 'creative': 12491,\n",
       " 'ほ': 566,\n",
       " '##臉': 18679,\n",
       " 'server': 8896,\n",
       " 'vol': 9218,\n",
       " '##墀': 14918,\n",
       " '侨': 905,\n",
       " '幼': 2405,\n",
       " '掖': 2962,\n",
       " 'air': 8523,\n",
       " '##一': 13728,\n",
       " '##燥': 17303,\n",
       " 'anti': 9204,\n",
       " '隱': 7403,\n",
       " 'd1': 11537,\n",
       " '椅': 3488,\n",
       " '##鉴': 20120,\n",
       " '##ますのて': 13071,\n",
       " '纜': 5271,\n",
       " 'focus': 11452,\n",
       " '##詛': 19326,\n",
       " '衅': 6119,\n",
       " '鎏': 7113,\n",
       " 'eba': 11129,\n",
       " 'imax': 11214,\n",
       " '酰': 6995,\n",
       " '##gnet': 13308,\n",
       " '##遴': 19961,\n",
       " 'cc': 8485,\n",
       " '涠': 3879,\n",
       " '##ead': 12943,\n",
       " '##擄': 16134,\n",
       " 'place': 10963,\n",
       " '##僑': 14066,\n",
       " '##赳': 19682,\n",
       " '##雎': 20478,\n",
       " '##妙': 15032,\n",
       " 'rmk': 13091,\n",
       " '喆': 1588,\n",
       " '怦': 2594,\n",
       " '颇': 7567,\n",
       " '璀': 4459,\n",
       " '##禦': 17945,\n",
       " '園': 1754,\n",
       " '##験': 20756,\n",
       " '##噎': 14738,\n",
       " '##宕': 15190,\n",
       " '101': 8359,\n",
       " 'si': 10883,\n",
       " 'ては': 9418,\n",
       " '忒': 2560,\n",
       " '瓶': 4486,\n",
       " '##呐': 14500,\n",
       " '##謝': 19399,\n",
       " '##導': 15263,\n",
       " '##到': 14225,\n",
       " '##塑': 14905,\n",
       " 'j': 152,\n",
       " '峴': 2293,\n",
       " 'ㄧ': 664,\n",
       " '##恢': 15669,\n",
       " '穆': 4946,\n",
       " 'ajax': 11569,\n",
       " '办': 1215,\n",
       " '##輕': 19795,\n",
       " '249': 10705,\n",
       " '團': 1757,\n",
       " '##桩': 16502,\n",
       " '伺': 848,\n",
       " '殁': 3649,\n",
       " '273': 10345,\n",
       " '儕': 1028,\n",
       " '猜': 4339,\n",
       " '賦': 6548,\n",
       " '静': 7474,\n",
       " '##ile': 9729,\n",
       " 'muji': 13001,\n",
       " '##65': 9331,\n",
       " '##穷': 18013,\n",
       " '##鲟': 20889,\n",
       " '●': 474,\n",
       " '肴': 5510,\n",
       " '##猕': 17391,\n",
       " '##:': 13332,\n",
       " '鑊': 7140,\n",
       " '##ction': 9116,\n",
       " '##late': 11523,\n",
       " '##啷': 14636,\n",
       " '##锑': 20287,\n",
       " 'du': 10173,\n",
       " 'lohasthree': 11741,\n",
       " 'のお': 8751,\n",
       " '##療': 17672,\n",
       " '龕': 7986,\n",
       " 'cookie': 8690,\n",
       " '##啥': 14624,\n",
       " '驚': 7711,\n",
       " 'bruce': 12897,\n",
       " 'app': 8172,\n",
       " 'font': 11851,\n",
       " '頌': 7520,\n",
       " '##蹟': 19752,\n",
       " '##菊': 18882,\n",
       " '##妪': 15040,\n",
       " '##曇': 16336,\n",
       " '艳': 5683,\n",
       " '116': 9070,\n",
       " 'doi': 9962,\n",
       " '##珈': 17451,\n",
       " 'する': 8553,\n",
       " '牺': 4295,\n",
       " '##師': 15431,\n",
       " '缔': 5354,\n",
       " '纫': 5280,\n",
       " '[unused95]': 95,\n",
       " '乌': 723,\n",
       " '咱': 1493,\n",
       " '##铂': 20246,\n",
       " '##蛐': 19087,\n",
       " '##↓': 12414,\n",
       " '畫': 4529,\n",
       " '##蝗': 19129,\n",
       " '褲': 6194,\n",
       " '取': 1357,\n",
       " '##侠': 13956,\n",
       " '##泛': 16850,\n",
       " '濯': 4096,\n",
       " '杷': 3349,\n",
       " '##walk': 12621,\n",
       " '##凑': 14179,\n",
       " '317': 11491,\n",
       " '扒': 2801,\n",
       " '呲': 1455,\n",
       " '##稷': 17995,\n",
       " 'url': 8654,\n",
       " '琢': 4423,\n",
       " '卒': 1293,\n",
       " '##柿': 16455,\n",
       " '燁': 4233,\n",
       " 'erp': 9529,\n",
       " '飕': 7602,\n",
       " '##翱': 18490,\n",
       " '摹': 3044,\n",
       " '驢': 7714,\n",
       " '495': 12895,\n",
       " '##応': 15622,\n",
       " '##陌': 20416,\n",
       " 'ˇ': 201,\n",
       " '汉': 3727,\n",
       " '##涉': 16925,\n",
       " '##苇': 18776,\n",
       " '##暂': 16314,\n",
       " '##莪': 18867,\n",
       " 'go': 8373,\n",
       " '嗷': 1643,\n",
       " '赳': 6625,\n",
       " '##54': 9488,\n",
       " '##011': 12424,\n",
       " 'audio': 11698,\n",
       " '##鹏': 20962,\n",
       " '##辛': 19846,\n",
       " '##迥': 19886,\n",
       " 'sunday': 11548,\n",
       " '##脱': 18621,\n",
       " '冢': 1095,\n",
       " '##仇': 13847,\n",
       " '猶': 4348,\n",
       " '##廃': 15497,\n",
       " '耳': 5455,\n",
       " '鞍': 7491,\n",
       " 'ネ': 617,\n",
       " '零': 7439,\n",
       " '##mw': 11504,\n",
       " 'bi': 11055,\n",
       " '赁': 6595,\n",
       " '虻': 6005,\n",
       " '##sun': 11798,\n",
       " '##泓': 16847,\n",
       " '##挛': 15965,\n",
       " '##郷': 20018,\n",
       " '◎': 473,\n",
       " '##多': 14971,\n",
       " '1925': 10087,\n",
       " '##↗': 13525,\n",
       " '毀': 3672,\n",
       " '烬': 4177,\n",
       " '##嫔': 15125,\n",
       " '##琴': 17490,\n",
       " '贩': 6575,\n",
       " '##跆': 19704,\n",
       " '##凸': 14194,\n",
       " '##盟': 17730,\n",
       " '[unused45]': 45,\n",
       " 'award': 11796,\n",
       " 'けます': 11841,\n",
       " '挽': 2924,\n",
       " 'most': 11344,\n",
       " '##蕭': 18998,\n",
       " 'swatch': 11876,\n",
       " '匾': 1279,\n",
       " '轼': 6769,\n",
       " '瓜': 4478,\n",
       " 'yy': 9453,\n",
       " '##kv': 11145,\n",
       " '##障': 20454,\n",
       " '888': 9389,\n",
       " '##尚': 15270,\n",
       " 'press': 9228,\n",
       " '##】': 13659,\n",
       " '宏': 2131,\n",
       " '##俑': 13977,\n",
       " '##厲': 14398,\n",
       " '##疾': 17622,\n",
       " '##頼': 20594,\n",
       " '##｜': 9815,\n",
       " '##坐': 14834,\n",
       " '可': 1377,\n",
       " '藿': 5977,\n",
       " '##㈦': 13725,\n",
       " '俺': 939,\n",
       " '##獺': 17424,\n",
       " '##sday': 12956,\n",
       " '栄': 3401,\n",
       " '缉': 5351,\n",
       " '蘆': 5978,\n",
       " '褒': 6187,\n",
       " '##晖': 16296,\n",
       " '##洼': 16891,\n",
       " '##he': 9977,\n",
       " '##皖': 17703,\n",
       " '##鋁': 20136,\n",
       " '懑': 2749,\n",
       " '炀': 4137,\n",
       " '街': 6125,\n",
       " '輾': 6747,\n",
       " '##汩': 16798,\n",
       " 'rna': 11656,\n",
       " '霹': 7465,\n",
       " '哲': 1528,\n",
       " '汁': 3723,\n",
       " '甩': 4501,\n",
       " 'icp': 9658,\n",
       " '##耍': 18503,\n",
       " 'factory': 12896,\n",
       " '##氈': 16750,\n",
       " '##胖': 18580,\n",
       " '邏': 6922,\n",
       " '##霉': 20507,\n",
       " 'β': 211,\n",
       " '觎': 6232,\n",
       " '##识': 19456,\n",
       " '##ang': 8688,\n",
       " '竿': 5004,\n",
       " '絳': 5188,\n",
       " '枋': 3357,\n",
       " '##kb': 10285,\n",
       " '##ov': 11689,\n",
       " '##鮨': 20858,\n",
       " '##岑': 15320,\n",
       " 'usb': 8335,\n",
       " '蟀': 6091,\n",
       " '##ケ': 13684,\n",
       " '##rey': 11492,\n",
       " '##小': 15264,\n",
       " '##绰': 18390,\n",
       " '448': 13078,\n",
       " '壽': 1904,\n",
       " '烯': 4179,\n",
       " '贵': 6586,\n",
       " '##壊': 14941,\n",
       " '##™': 9221,\n",
       " '瘸': 4613,\n",
       " '##跖': 19709,\n",
       " '遲': 6903,\n",
       " '##実': 15199,\n",
       " 'れ': 581,\n",
       " '##稚': 17985,\n",
       " '扪': 2811,\n",
       " '樣': 3564,\n",
       " '##lam': 12953,\n",
       " '##这': 19878,\n",
       " '##迅': 19870,\n",
       " '##tag': 11882,\n",
       " '##附': 20410,\n",
       " '壳': 1900,\n",
       " '賤': 6547,\n",
       " '##ris': 9848,\n",
       " '##儂': 14079,\n",
       " '膦': 5609,\n",
       " 'national': 9385,\n",
       " '顺': 7556,\n",
       " '##捎': 15990,\n",
       " '舆': 5644,\n",
       " 'at': 8243,\n",
       " '##熄': 17276,\n",
       " '##荽': 18853,\n",
       " '涤': 3882,\n",
       " '編': 5226,\n",
       " 'joy': 12668,\n",
       " '##覬': 19275,\n",
       " '##肖': 18551,\n",
       " '癮': 4628,\n",
       " '瞭': 4747,\n",
       " '##茴': 18818,\n",
       " '115': 8787,\n",
       " '##擠': 16146,\n",
       " 'なら': 12604,\n",
       " 'はい': 9781,\n",
       " '薰': 5962,\n",
       " 'ᅭ': 314,\n",
       " '##锆': 20280,\n",
       " '##絨': 18241,\n",
       " '##阈': 20385,\n",
       " 'orz': 10836,\n",
       " '猛': 4338,\n",
       " '##cher': 10824,\n",
       " 'していると': 11915,\n",
       " 'street': 9471,\n",
       " '##淪': 16971,\n",
       " '##壅': 14938,\n",
       " '##陸': 20437,\n",
       " '08': 8142,\n",
       " 'dv': 12372,\n",
       " '姓': 1998,\n",
       " '##败': 19628,\n",
       " 'ます': 11105,\n",
       " '成': 2768,\n",
       " '##哔': 14573,\n",
       " '酩': 6990,\n",
       " '2002': 8301,\n",
       " '##靚': 20532,\n",
       " '##差': 15402,\n",
       " '徐': 2528,\n",
       " '##孙': 15158,\n",
       " '##觑': 19291,\n",
       " '価': 900,\n",
       " '囤': 1732,\n",
       " '⋅': 401,\n",
       " '矚': 4756,\n",
       " '##槐': 16600,\n",
       " '楞': 3506,\n",
       " '蠣': 6112,\n",
       " '赓': 6607,\n",
       " '鑣': 7143,\n",
       " '[CLS]': 101,\n",
       " '##囡': 14786,\n",
       " '让': 6375,\n",
       " 'mama': 13186,\n",
       " '##oh': 12355,\n",
       " '洲': 3828,\n",
       " '墜': 1871,\n",
       " '##￣': 21122,\n",
       " '##絕': 18236,\n",
       " '1893': 12927,\n",
       " '##mi': 8625,\n",
       " 'へ': 565,\n",
       " '旎': 3183,\n",
       " '##萧': 18911,\n",
       " '##驅': 20762,\n",
       " '矮': 4765,\n",
       " '∮': 387,\n",
       " '熄': 4219,\n",
       " 'miss': 9368,\n",
       " '##荪': 18845,\n",
       " 'party': 9126,\n",
       " '##粗': 18167,\n",
       " 'せからこ': 12150,\n",
       " '##初': 14216,\n",
       " '##跑': 19708,\n",
       " '012': 11496,\n",
       " '##74': 9743,\n",
       " '仙': 803,\n",
       " '##嘣': 14720,\n",
       " 'sodu': 9637,\n",
       " '脐': 5553,\n",
       " 'smith': 9912,\n",
       " '赤': 6619,\n",
       " '鍥': 7105,\n",
       " '##囊': 14775,\n",
       " '##首': 20731,\n",
       " '##抢': 15900,\n",
       " '筠': 5035,\n",
       " '##殒': 16713,\n",
       " '##纤': 18332,\n",
       " '##殡': 16718,\n",
       " '▲topmar': 10172,\n",
       " '##罌': 18436,\n",
       " 'tech': 11402,\n",
       " '##狄': 17370,\n",
       " '##嵇': 15370,\n",
       " '##鹧': 20970,\n",
       " '427': 12575,\n",
       " '##妘': 15031,\n",
       " '##湃': 17012,\n",
       " '##钨': 20230,\n",
       " '890': 12075,\n",
       " 'taipei': 9858,\n",
       " '任': 818,\n",
       " '庭': 2431,\n",
       " '怡': 2592,\n",
       " '续': 5330,\n",
       " '臼': 5639,\n",
       " '蛮': 6037,\n",
       " '蜚': 6056,\n",
       " '##14': 8717,\n",
       " 'gmp': 10821,\n",
       " 'pk10': 9329,\n",
       " '嫡': 2072,\n",
       " '##躊': 19768,\n",
       " '別': 1162,\n",
       " '52sykb': 12846,\n",
       " '##que': 9477,\n",
       " '##粑': 18164,\n",
       " '##槤': 16605,\n",
       " '殇': 3652,\n",
       " '淵': 3920,\n",
       " '藻': 5976,\n",
       " '##责': 19626,\n",
       " '##ld': 8635,\n",
       " '##翼': 18494,\n",
       " 'htm': 9645,\n",
       " '筐': 5028,\n",
       " '琪': 4427,\n",
       " '##\\u2028': 13502,\n",
       " '##综': 18398,\n",
       " '惜': 2667,\n",
       " '##ᄐ': 13467,\n",
       " '##⒉': 13572,\n",
       " '##乘': 13790,\n",
       " '##蚓': 19070,\n",
       " '##褓': 19245,\n",
       " '琬': 4428,\n",
       " '##帥': 15428,\n",
       " '势': 1232,\n",
       " '咕': 1475,\n",
       " 'gsm': 11484,\n",
       " '##涩': 16943,\n",
       " '##裔': 19224,\n",
       " '咽': 1498,\n",
       " '瑰': 4456,\n",
       " '##ort': 10143,\n",
       " '##و': 13439,\n",
       " '嘞': 1660,\n",
       " '▲topnov': 10502,\n",
       " '砚': 4780,\n",
       " '砺': 4791,\n",
       " '＞': 8042,\n",
       " '##勐': 14295,\n",
       " '撅': 3049,\n",
       " '皂': 4637,\n",
       " '盤': 4676,\n",
       " '##修': 13991,\n",
       " '##证': 19452,\n",
       " '[unused29]': 29,\n",
       " '肤': 5502,\n",
       " 'dance': 12371,\n",
       " '##潑': 17105,\n",
       " '##舍': 18707,\n",
       " '##絢': 18239,\n",
       " '掐': 2960,\n",
       " 'not': 9059,\n",
       " '食': 7608,\n",
       " '饕': 7642,\n",
       " '##忙': 15621,\n",
       " '##巫': 15401,\n",
       " '坂': 1771,\n",
       " '##耽': 18517,\n",
       " 'natural': 12627,\n",
       " '哄': 1503,\n",
       " '菸': 5839,\n",
       " 'blogfp': 10207,\n",
       " '##使': 13943,\n",
       " 'matlab': 12640,\n",
       " '##让': 19432,\n",
       " '##tr': 11309,\n",
       " '靴': 7486,\n",
       " '##踐': 19730,\n",
       " 'jcb': 10557,\n",
       " '##ing': 8221,\n",
       " '##sn': 12480,\n",
       " '##ston': 10229,\n",
       " '##績': 18302,\n",
       " '##究': 18012,\n",
       " '12345678910': 9363,\n",
       " 'body': 9867,\n",
       " 'đ': 195,\n",
       " '像': 1008,\n",
       " '徳': 2545,\n",
       " '韻': 7512,\n",
       " '##瀑': 17162,\n",
       " '##nger': 11533,\n",
       " '##柬': 16448,\n",
       " '##曠': 16342,\n",
       " '##襬': 19259,\n",
       " 'inc': 8910,\n",
       " '##66': 8952,\n",
       " '詆': 6265,\n",
       " '##弃': 15518,\n",
       " \"'\": 112,\n",
       " '炽': 4160,\n",
       " '阅': 7325,\n",
       " '##ire': 9764,\n",
       " 'てきます': 11397,\n",
       " '154': 9220,\n",
       " 'pixel': 11688,\n",
       " '##銓': 20126,\n",
       " '870': 10731,\n",
       " '諷': 6327,\n",
       " '鄭': 6972,\n",
       " '禮': 4891,\n",
       " '##ga': 8676,\n",
       " '##虫': 19058,\n",
       " '##貌': 19562,\n",
       " '巽': 2352,\n",
       " '##笼': 18078,\n",
       " '截': 2779,\n",
       " '拖': 2870,\n",
       " '故': 3125,\n",
       " '嘅': 1646,\n",
       " '##鼹': 21021,\n",
       " '1gb': 12206,\n",
       " '##佞': 13927,\n",
       " '缢': 5363,\n",
       " '2004': 8258,\n",
       " '##皈': 17698,\n",
       " '玄': 4371,\n",
       " '701': 12656,\n",
       " '餵': 7633,\n",
       " '境': 1862,\n",
       " '鑲': 7146,\n",
       " '##123': 9807,\n",
       " '鸨': 7888,\n",
       " '澹': 4079,\n",
       " '##鍵': 20164,\n",
       " '##峇': 15337,\n",
       " '炙': 4147,\n",
       " '0755': 10960,\n",
       " '##購': 19611,\n",
       " '##泰': 16862,\n",
       " 'tue': 8483,\n",
       " '##禅': 17940,\n",
       " 'により': 11301,\n",
       " '技': 2825,\n",
       " '颅': 7565,\n",
       " '##抒': 15887,\n",
       " 'θ': 216,\n",
       " '智': 3255,\n",
       " '願': 7544,\n",
       " '##帐': 15419,\n",
       " '喏': 1594,\n",
       " '##痱': 17646,\n",
       " 'agoda': 8678,\n",
       " '##ay': 8760,\n",
       " '##侑': 13951,\n",
       " '洁': 3815,\n",
       " '##柳': 16451,\n",
       " '##tra': 9808,\n",
       " '##滿': 17078,\n",
       " '##羚': 18460,\n",
       " 'time': 8759,\n",
       " 'vsa': 10920,\n",
       " 'yam': 8107,\n",
       " '愉': 2690,\n",
       " '滸': 4019,\n",
       " '眸': 4704,\n",
       " '##喇': 14646,\n",
       " '袞': 6155,\n",
       " '##搏': 16068,\n",
       " '##铺': 20272,\n",
       " '宵': 2156,\n",
       " '讨': 6374,\n",
       " '##栗': 16469,\n",
       " '架': 3373,\n",
       " '##xi': 10201,\n",
       " '##鴉': 20914,\n",
       " '氏': 3694,\n",
       " '輟': 6741,\n",
       " '##ible': 12413,\n",
       " '##ation': 8794,\n",
       " '##攤': 16170,\n",
       " '##竇': 18044,\n",
       " '##菡': 18891,\n",
       " '##贏': 19617,\n",
       " 'line': 8323,\n",
       " '##櫃': 16659,\n",
       " 'series': 10976,\n",
       " '☞': 483,\n",
       " '##仕': 13856,\n",
       " '蜀': 6043,\n",
       " 'jerry': 13111,\n",
       " '132': 9306,\n",
       " '綿': 5214,\n",
       " '##芸': 18769,\n",
       " '82': 8460,\n",
       " '##缕': 18412,\n",
       " '##board': 9472,\n",
       " '溯': 3985,\n",
       " '##操': 16139,\n",
       " 'にお': 10768,\n",
       " '瀚': 4108,\n",
       " '匯': 1274,\n",
       " '2011': 8163,\n",
       " '##ンター': 11223,\n",
       " '##代': 13864,\n",
       " '嘣': 1663,\n",
       " '##綻': 18268,\n",
       " 'ᆼ': 328,\n",
       " '棵': 3484,\n",
       " '温': 3946,\n",
       " '##鹘': 20965,\n",
       " '##飪': 20669,\n",
       " '##惶': 15741,\n",
       " '价': 817,\n",
       " '##业': 13746,\n",
       " '##炜': 17205,\n",
       " '漳': 4040,\n",
       " 'zero': 10397,\n",
       " '##泸': 16867,\n",
       " '屋': 2238,\n",
       " '覓': 6212,\n",
       " '##绎': 18363,\n",
       " '槌': 3540,\n",
       " '##珂': 17449,\n",
       " '##ㄞ': 13717,\n",
       " '瑄': 4440,\n",
       " '##ise': 9651,\n",
       " '辩': 6796,\n",
       " '##铢': 20259,\n",
       " '##残': 16712,\n",
       " '##溱': 17043,\n",
       " '##ml': 8477,\n",
       " '##超': 19688,\n",
       " '##煊': 17258,\n",
       " '曼': 3294,\n",
       " '##伞': 13892,\n",
       " '译': 6406,\n",
       " '##侗': 13953,\n",
       " '匿': 1280,\n",
       " '㊣': 668,\n",
       " '##asia': 11276,\n",
       " 'docomo': 11358,\n",
       " 'ゃ': 572,\n",
       " '広': 2410,\n",
       " '剎': 1185,\n",
       " '##塞': 14910,\n",
       " '導': 2206,\n",
       " '柔': 3382,\n",
       " 'jimmy': 10317,\n",
       " '展': 2245,\n",
       " '鋒': 7081,\n",
       " 'wikipedia': 11850,\n",
       " '##嘯': 14726,\n",
       " '##琲': 17488,\n",
       " '##2008': 10545,\n",
       " '椎': 3491,\n",
       " '囪': 1734,\n",
       " '##纔': 18326,\n",
       " '埼': 1826,\n",
       " '##跄': 19703,\n",
       " '##⒈': 13571,\n",
       " '##戕': 15828,\n",
       " '##﹑': 21058,\n",
       " '巒': 2332,\n",
       " '歙': 3629,\n",
       " '##璉': 17520,\n",
       " '樽': 3574,\n",
       " '鐵': 7136,\n",
       " '舔': 5654,\n",
       " 'zenfone': 11726,\n",
       " '##乜': 13792,\n",
       " '##－': 21081,\n",
       " '##貢': 19570,\n",
       " '119': 9031,\n",
       " '##劃': 14262,\n",
       " 'top10': 10466,\n",
       " 'g': 149,\n",
       " '##曲': 16346,\n",
       " '爬': 4260,\n",
       " '角': 6235,\n",
       " '卉': 1287,\n",
       " '午': 1286,\n",
       " '##創': 14258,\n",
       " '##′': 13504,\n",
       " '##薑': 19009,\n",
       " '##血': 19174,\n",
       " '觊': 6231,\n",
       " '##津': 16880,\n",
       " '##濺': 17155,\n",
       " '##楞': 16563,\n",
       " 'level': 9888,\n",
       " '脹': 5568,\n",
       " '430': 10352,\n",
       " '〗': 529,\n",
       " '##tta': 11245,\n",
       " '##摔': 16092,\n",
       " '允': 1038,\n",
       " '##資': 19593,\n",
       " '##sch': 13107,\n",
       " 'ぃ': 535,\n",
       " '##けと': 10095,\n",
       " '##仮': 13870,\n",
       " '##祥': 17929,\n",
       " '宋': 2129,\n",
       " '鯽': 7811,\n",
       " '##脚': 18615,\n",
       " '##块': 14836,\n",
       " 'richard': 9875,\n",
       " '##組': 18232,\n",
       " '##脑': 18611,\n",
       " '##餒': 20681,\n",
       " 'st': 8811,\n",
       " 'з': 240,\n",
       " '##曬': 16344,\n",
       " '咔': 1474,\n",
       " '##ᄇ': 13460,\n",
       " '123456': 10644,\n",
       " 'ago': 8498,\n",
       " '咙': 1479,\n",
       " '##int': 9824,\n",
       " '91tv': 12586,\n",
       " '坊': 1773,\n",
       " '##愕': 15750,\n",
       " '妊': 1969,\n",
       " '捂': 2926,\n",
       " '##覇': 19266,\n",
       " '沽': 3782,\n",
       " '##撂': 16104,\n",
       " '##ｏ': 9940,\n",
       " '##51': 9216,\n",
       " '##瞒': 17794,\n",
       " '祛': 4865,\n",
       " '##if': 9536,\n",
       " 'iptv': 12844,\n",
       " '埔': 1815,\n",
       " '##榜': 16585,\n",
       " 'general': 11568,\n",
       " '学': 2110,\n",
       " '##游': 17009,\n",
       " '被': 6158,\n",
       " 'dd': 10391,\n",
       " 'e2': 12357,\n",
       " 'hgih': 11674,\n",
       " '亘': 760,\n",
       " '蒲': 5891,\n",
       " '三': 676,\n",
       " '蝟': 6074,\n",
       " '##64': 9165,\n",
       " 'shop': 9926,\n",
       " '革': 7484,\n",
       " '##開': 20331,\n",
       " '##條': 16511,\n",
       " 'fgo': 11401,\n",
       " '##戰': 15839,\n",
       " 'hk': 8512,\n",
       " '窿': 4984,\n",
       " '##琐': 17478,\n",
       " '毯': 3691,\n",
       " '##雑': 20480,\n",
       " '撻': 3071,\n",
       " '飼': 7615,\n",
       " '##ᄌ': 13464,\n",
       " '450': 8802,\n",
       " '##nome': 13125,\n",
       " '##彝': 15557,\n",
       " '##new': 10654,\n",
       " 'games': 10810,\n",
       " '##粼': 18180,\n",
       " '##ⅲ': 13521,\n",
       " '##澀': 17123,\n",
       " '洪': 3825,\n",
       " '钠': 7165,\n",
       " '218': 10224,\n",
       " '##lux': 12700,\n",
       " 'ふ': 564,\n",
       " 'schemas': 11847,\n",
       " '佤': 875,\n",
       " '##800': 9988,\n",
       " '##酐': 20039,\n",
       " 'make': 9994,\n",
       " '1947': 9253,\n",
       " '##贿': 19651,\n",
       " '##ound': 11477,\n",
       " '##諸': 19385,\n",
       " '##怔': 15642,\n",
       " '琐': 4421,\n",
       " '##狂': 17369,\n",
       " '##龋': 21038,\n",
       " '壟': 1890,\n",
       " '锯': 7242,\n",
       " '賁': 6532,\n",
       " '##钤': 20226,\n",
       " '俪': 931,\n",
       " '##再': 14143,\n",
       " '##淡': 16966,\n",
       " '##ᅦ': 13473,\n",
       " '##ane': 10581,\n",
       " '##讪': 19433,\n",
       " '##侣': 13958,\n",
       " 'exhibition': 13282,\n",
       " '鉄': 7055,\n",
       " '##癱': 17686,\n",
       " '##倏': 14003,\n",
       " '##よ': 9427,\n",
       " '##孃': 15150,\n",
       " ...}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['我', '欲', '乘', '风']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(input_text)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2769, 3617, 733, 7599]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['我', '欲', '乘', '风']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(ids)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 2769, 3617, 733, 7599, 102]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = tokenizer.encode(input_text)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'我 欲 乘 风'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_sen = tokenizer.decode(ids, skip_special_tokens=True)\n",
    "str_sen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 填充与截断"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 2769, 3617, 733, 7599, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = tokenizer.encode(str_sen, padding='max_length', max_length=15)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = tokenizer.encode(str_sen, max_length=5, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2769, 3617, 733, 7599, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer.encode_plus(str_sen, padding='max_length', max_length=15)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['token_type_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 2769, 3617, 733, 7599, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2769, 3617, 733, 7599, 8024, 2769, 3617, 7607, 5425, 102, 0, 0, 0, 0], [101, 2769, 3617, 733, 7599, 8024, 2769, 3617, 7607, 5425, 8024, 2769, 3617, 5433, 5425, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sens = ['我欲乘风', '我欲乘风，我欲飞翔', '我欲乘风，我欲飞翔，我欲翱翔']\n",
    "res = tokenizer(sens, padding='max_length', max_length=15)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm-6b:\n",
      "- tokenization_chatglm.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "loading file ice_text.model from cache at /home/bigorange/.cache/huggingface/hub/models--THUDM--chatglm-6b/snapshots/bf0f5cfb575eebebf9b655c5861177acfee03f16/ice_text.model\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/bigorange/.cache/huggingface/hub/models--THUDM--chatglm-6b/snapshots/bf0f5cfb575eebebf9b655c5861177acfee03f16/tokenizer_config.json\n",
      "loading file tokenizer.json from cache at None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ChatGLMTokenizer' object has no attribute 'sp_tokenizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTHUDM/chatglm-6b\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/CS224N/lib/python3.9/site-packages/transformers/models/auto/tokenization_auto.py:892\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    890\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(pretrained_model_name_or_path):\n\u001b[1;32m    891\u001b[0m         tokenizer_class\u001b[38;5;241m.\u001b[39mregister_for_auto_class()\n\u001b[0;32m--> 892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m config_tokenizer_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    896\u001b[0m     tokenizer_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/CS224N/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2208\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2205\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2206\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from cache at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresolved_vocab_files[file_id]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresolved_vocab_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2211\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_configuration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2212\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2216\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2217\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_is_local\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2219\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2220\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/CS224N/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2442\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._from_pretrained\u001b[0;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2440\u001b[0m \u001b[38;5;66;03m# Instantiate the tokenizer.\u001b[39;00m\n\u001b[1;32m   2441\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2442\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2443\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m import_protobuf_decode_error():\n\u001b[1;32m   2444\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m   2445\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to load tokenizer model from SPM, loading from TikToken will be attempted instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2446\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(Google protobuf error: Tried to load SPM model with non-SPM vocab file).\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2447\u001b[0m     )\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/THUDM/chatglm-6b/bf0f5cfb575eebebf9b655c5861177acfee03f16/tokenization_chatglm.py:196\u001b[0m, in \u001b[0;36mChatGLMTokenizer.__init__\u001b[0;34m(self, vocab_file, do_lower_case, remove_space, bos_token, eos_token, end_token, mask_token, gmask_token, padding_side, pad_token, unk_token, num_image_tokens, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    181\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    182\u001b[0m         vocab_file,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    195\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_lower_case\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_lower_case\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremove_space\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremove_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbos_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbos_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meos_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mend_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgmask_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgmask_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43munk_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munk_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_image_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_image_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_lower_case \u001b[38;5;241m=\u001b[39m do_lower_case\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremove_space \u001b[38;5;241m=\u001b[39m remove_space\n",
      "File \u001b[0;32m~/miniconda3/envs/CS224N/lib/python3.9/site-packages/transformers/tokenization_utils.py:436\u001b[0m, in \u001b[0;36mPreTrainedTokenizer.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    434\u001b[0m \u001b[38;5;66;03m# 4. If some of the special tokens are not part of the vocab, we add them, at the end.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;66;03m# the order of addition is the same as self.SPECIAL_TOKENS_ATTRIBUTES following `tokenizers`\u001b[39;00m\n\u001b[0;32m--> 436\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_tokens\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_special_tokens_extended\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_added_tokens_encoder\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspecial_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decode_use_source_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/CS224N/lib/python3.9/site-packages/transformers/tokenization_utils.py:544\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._add_tokens\u001b[0;34m(self, new_tokens, special_tokens)\u001b[0m\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m added_tokens\n\u001b[1;32m    543\u001b[0m \u001b[38;5;66;03m# TODO this is fairly slow to improve!\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m current_vocab \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    545\u001b[0m new_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(current_vocab)  \u001b[38;5;66;03m# only call this once, len gives the last index + 1\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m new_tokens:\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/THUDM/chatglm-6b/bf0f5cfb575eebebf9b655c5861177acfee03f16/tokenization_chatglm.py:248\u001b[0m, in \u001b[0;36mChatGLMTokenizer.get_vocab\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_vocab\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    247\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Returns vocab as a dict \"\"\"\u001b[39;00m\n\u001b[0;32m--> 248\u001b[0m     vocab \u001b[38;5;241m=\u001b[39m {\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_id_to_token(i): i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_size\u001b[49m)}\n\u001b[1;32m    249\u001b[0m     vocab\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madded_tokens_encoder)\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m vocab\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/THUDM/chatglm-6b/bf0f5cfb575eebebf9b655c5861177acfee03f16/tokenization_chatglm.py:244\u001b[0m, in \u001b[0;36mChatGLMTokenizer.vocab_size\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvocab_size\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    243\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Returns vocab size \"\"\"\u001b[39;00m\n\u001b[0;32m--> 244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msp_tokenizer\u001b[49m\u001b[38;5;241m.\u001b[39mnum_tokens\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ChatGLMTokenizer' object has no attribute 'sp_tokenizer'"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('THUDM/chatglm-6b', trust_remote_code = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS224N",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
